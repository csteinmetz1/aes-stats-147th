,title,abstract,authors,affiliation,subject,paper_type
0,Mental Representations in Critical Listening Education: A Preliminary Study,"This paper reports on a survey of critical listening training offered at tertiary education providers in the USA, UK, Australia, and Canada. The purpose of the investigation is to explore the concept of mental representations in educational contexts, as instructional materials do not always consider this aspect despite a rich research terrain in the field. The analysis shows a wide diversity of instructional methods used, seemingly influenced by course subject matter and institution business model. It also reveals a need to accurately define the concept of critical listening, depending on the context of its use. This study provides the background to a proposed evaluation of the effectiveness of mental representation models applied to new instructional designs.","['Elmosnino, Stephane']","['University of Technology Sydney, Sydney, New South Wales, Australia']",Audio Education,Talk
1,Audio Data Augmentation for Road Objects Classification by an Artificial Neural Network,"Following the resurgence of machine learning within the context of autonomous driving, the need for acquiring and labeling data expanded by folds. Despite the large amount of available visual data (images, point clouds, . . . ), researchers apply augmentation techniques to extend the training dataset, which improves the classification accuracy. When trying to exploit audio data for autonomous driving, two challenges immediately surfaced: first, the lack of available data and second, the absence of augmentation techniques. In this paper we introduce a series of augmentation techniques suitable for audio data. We apply several procedures, inspired by data augmentation for image classification, that transform and distort the original data to produce similar effects on sound. We show the increase in overall accuracy of our neural network for sound classification by comparing it to the non-augmented version.","['Barak, Ohad', 'Sallem, Nizar']","['Mentor Graphics, Mountain View, CA, USA']",Applications in Audio,Poster
2,Generative Modeling of Metadata for Machine Learning Based Audio Content Classification,"Automatic content classification technique is an essential tool in multimedia applications. Present research for audio-based classifiers look at short- and long-term analysis of signals, using both temporal and spectral features. In this paper we present a neural network to classify between the movie (cinematic, TV shows), music, and voice using metadata contained in either the audio/video stream. Towards this end, statistical models of the various metadata are created since a large metadata dataset is not available. Subsequently, synthetic metadata are generated from these statistical models, and the synthetic metadata is input to the ML classifier as feature vectors. The resulting classifier is then able to classify real-world content (e.g., YouTube) with an accuracy ˜ 90% with very low latency (viz., ˜ on an average 7 ms) based on real-world metadata.","['Bharitkar, Sunil G.']","['HP Labs., Inc., San Francisco, CA, USA']",Applications in Audio,Talk
3,Personal Sound Zones: A Comparison between Frequency and Time Domain Formulations in a Transportation Context,"This paper compares the formulation of a least-squares pressure matching algorithm in the frequency and time domains for the generation of Personal Sound Zones (PSZ) for a transportation application. Due to variations in the transportation’s acoustic environment, the calculation time is added to the usually found metrics in the PSZ bibliography (like Acoustic Contrast, Effort, etc.). Both formulations are implemented to control two zones in three configurations (4, 6, and 8 sources), using monopole simulations and anechoic measurements. In spite of not always presenting perfectly causal filters—pre-ringing in some filters occurs in some cases—the frequency domain formulation allows achieving equal levels of Acoustic Contrast, Effort, and Reproduction error more than 500 times faster than the time domain formulation.","['Vindrola, Lucas', 'Melon, Manuel', 'Chamard, Jean-Christophe', 'Gazengel, Bruno', 'Plantier, Guy']","['PSA Group, Rueil-Malmaison, France', 'Le Mans Université, Le Mans cedex 9, France']",Applications in Audio,Talk
4,Acoustic Beamforming on Transverse Loudspeaker Array Constructed from Micro-Speakers Point Sources for Effectiveness Improvement in High-Frequency Range,"Variable directivity speaker arrays are very popular in many acoustic aspects, such as wearable systems, natural sources simulations or acoustic scanners. Standard systems constructed from traditional drivers, despite great DSP, have limited beamforming possibilities because of the very narrow directivity patterns for loudspeakers in high frequencies. This paper presents a new approach for micro-speakers array design from monopole sources, based on isobaric speaker configuration. New solutions allow to reach high efficiency in broadband frequency range keeping matrix size small. This presentation will contain an explanation of used isobaric speaker principles and comparisons between standard transverse transducers matrix and innovative point-source matrix in two configurations. Achieved results allow to improve beamforming effectiveness in a high frequency range with new driver matrix construction.","['Chojnacki, Bartlomiej', 'Juros, Klara', 'Kaczor, Daniel', 'Kamisinski, Tadeusz']","['AGH University of Science and Technology, Cracow, Poland']",Transducers,Poster
5,Evaluating Four Variants of Sine Sweep Techniques for Their Resilience to Noise in Room Acoustic Measurements,"The sine sweep is one of the most effective methods for measuring room impulse responses; however, ambient room noise or unpredictable impulsive noises can negatively affect the quality of the measurement. This study evaluates four different variants of sine sweeps techniques for their resilience to noise when used as an excitation signal in room impulse response measurements: linear, exponential, noise whitened, and minimum noise. The result shows that in a pseudo-anechoic environment, exponential and linear sine sweeps are most resilient to impulsive noise among the four sweeps, while none of the evaluated sine sweeps are resilient to impulsive noise in an acoustically untreated room. Additionally, it is shown that minimum noise sine sweeps are most resilient to ambient noise.","['Segerstrom, Eric', 'Lee, Ming-Lun', 'Philbert, Steve']","['Rensselaer Polytechnic Institute, Troy, NY, USA', 'University of Rochester, Rochester, NY, USA']",Applications in Audio,Poster
6,"Designing Listening Tests of SR/PA Systems, A Case Study","It is very common to arrange for comparisons of SR/PA-systems. However, often, these comparisons are organized in a way leaving procedures less transparent and results rather unclear. Standards for the assessment of loudspeakers do exist. The assessors basically must be trained for the purpose, and the set-up should support double-blind testing. However, in the test of big systems, the listening panel is not necessarily trained, and the practical problems of rigging huge arrays to some degree may weaken the procedures and the results. This paper describes considerations for the comparative assessment of SR/PA systems. The paper also reports the outcome of an experiment where considered principles were applied.","['Brixen, Eddy Bøgh']","['EBB-consult, Smørum, Denmark', 'DPA Microphones, Allerød, Denmark']",Transducers,Talk
7,Temporal Envelope-Based Psychoacoustic Modelling for Evaluating Non-Waveform Preserving Audio Codecs,"Masking models that evaluate the audibility of error signals have a limited validity for assessing perceptual quality of parametric codecs. We propose a model that transforms the audio signal into an Internal Representation (IR) consisting of temporal-envelope modulation patterns. Subsequently, the IR of original and encoded signals are compared between both signals. Even though the audio signals compared may be uncorrelated, leading to a large error signal, they may exhibit a very similar IR and hence are predicted to sound very similar. Additional post-processing stages modeling higher-level auditory perceptual phenomena such as Comodulation Masking Release are included. Predictions are compared against subjective quality assessment results obtained with encoding methods ranging from parametric processing methods up to classic waveform preserving codecs.","['van de Par, Steven', 'Disch, Sascha', 'Niedermeier, Andreas', 'Burdiel Pérez, Elena', 'Edler, Bernd']","['University of Oldenburg, Oldenburg, Germany', 'Fraunhofer Institute for Integrated Circuits IIS, Erlangen, Germany', 'Friedrich Alexander University, Erlangen-Nürnberg, Germany', 'Fraunhofer HAS, Oldenburg, Germany']",Product Development,Talk
8,Personalized and Self-Adapting Headphone Equalization Using Near Field Response,"Variability in the acoustical coupling of headphones to human ears depends on a number of factors. Placement, size of user’s head and ears, the headband and ear-pad material are all major contributors to the sound quality delivered by the headphone to the user. By measuring the transfer function from the driver terminals to a miniature microphone set near the driver inside the cavity produced by the headphone and the ear, the degree of acoustical coupling and the fundamental frequency of the cavity volume was acquired. An individualized equalization on these measurements was applied to every user. Listeners rated the personalized EQ significantly higher than a generic target response and slightly higher than the bypassed headphone.","['Celestinos, Adrian', 'McMullin, Elisabeth', 'Banka, Ritesh', 'Brunet, Pascal']","['Samsung Research America, Valencia, CA, USA']",Transducers,Poster
9,Preference for Harmonic Intervals Based on Overtone Content of Complex Tones,"This study investigated whether or not overtone structure generated preferential differences for harmonic intervals. The purpose of this study was to determine if the structure of a complex tone affects the perception of consonance in harmonic intervals. Prior studies suggest harmonicity as the basis for so-called “consonance” while others suggest exact ratios are not necessary. This test examined listener responses across three tonal “types” through a randomized double-blind trinomial forced-choice format. Stimuli types used full, odd, and even overtone series at three relative-magnitude loudness levels. Results revealed no effect of loudness and a generalized but highly variable trend for the even overtone series. However, some subjects exhibited a very strong preference for certain overtone combinations, while others demonstrated no preference.","['Fox, Benjamin', 'Bulla, Wesley']","['Belmont University, Nashville, TN, USA']",Perception,Poster
10,Tetrahedral Microphones: An Effective A/B Main System,"A simple approach to produce an effective stereo main audio recording system using tetrahedral microphones is described, capturing a full array of close and distant sound with a substantial amount of early reflections. This allows for the easy possibility of later surround or 3D reproduction. Furthermore, the implementation of a pragmatic and simple two-microphone set-up can lead to an efficient capture of the stereo soundfield that has many applications. Particular attention was paid to binaural mixing of this microphone system to demonstrate an easy first step into immersive reproduction of the sound.","['Dobson, Alexander', 'Woszczyk, Wieslaw']","['McGill University, Montreal, QC, Canada']",Spatial Audio,Talk
11,On the Similarity between Feedback/Loopback Amplitude and Frequency Modulation,"This paper extends previous work in loopback frequency modulation (FM) to a similar system in which an oscillator is looped back to modulate its own amplitude, so called feedback amplitude modulation (FBAM). A continuous-time closed-form solution is presented for each, yielding greatly improved numerical properties, reduced dependency on sampling rate, and a more accurate representation of the feedback by eliminating the unit-sample delay required for discrete-time implementation. Producing similar waveforms, it is shown that FBAM for a known input frequency, is actually a scaled and offset version of loopback FM having a different carrier frequency but same sounding frequency. Two distinct representations are used to show mathematical equivalence between systems while validating the closed-form solution for each.","['Smyth, Tamara']","['University of California, San Diego, San Diego, CA, USA']",Audio Signal Processing,Talk
12,Concert Hall Acoustics' Influence on the Tempo of Musical Performances,"The acoustics of a concert hall is an integral and significant part of a musical performance as it affects the artistic decisions made by performer. Still, there are few systematic studies on the phenomenon. In this paper the effect of concert hall acoustics, mainly reverberation, on musical tempo for a selection of different genres and ensemble types is analyzed quantitatively. The study utilizes audio recordings made in a concert hall equipped with a movable ceiling enabling a variable volume and thus a variable reverberation time. The results show that there are cases where the tempo follows a change in acoustics as well as cases where it remains more or less unchanged.","['Berg, Jan']","['Luleå University of Technology, Piteå, Sweden']",Room Acoustics,Talk
13,Forensic Comparison of Simultaneous Recordings of Gunshots at a Crime Scene,"Audio forensic evidence is of increasing importance in law enforcement investigations because of the growing use in the United States of personal audio/video recorders carried by officers on duty, by bystanders, and by surveillance systems of businesses and residences. These recording systems capture speech, background environmental sounds, and in some cases, gunshots and other firearm sounds. When there are multiple audio recording devices near the scene of a gunfire incident, the similarities and differences of the various recordings can either help or hamper the audio forensic examiner’s efforts to describe the sequence of events. This paper considers several examples and provides recommendations for audio forensic examiners in the interpretation of this gunshot acoustic evidence.","['Maher, Robert C.', 'Hoerr, Ethan']","['Montana State University, Bozeman, MT, USA']",Semantic Audio,Talk
14,A Comparative Pilot Study and Analysis of Audio Mixing Using Logic Pro X and GarageBand for iOS,"In this pilot study we compare two mixes of a song done with GarageBand on iOS and Logic Pro X in a professional studio environment. The audio tracks are recorded and mastered in the same controlled environment by the same engineer. A blind listening survey was given to 10 laypersons and 10 professional studio engineers who have at least 10 years of related experience. 80% lay persons and 60% professional studio engineers reported a higher preference for the Logic Pro X version. To further compare these two productions, we look at (1) short-term perceptual loudness to quantify dynamic range and (2) power spectral densities in different frequency bands to quantify EQ. The analysis provides evidence to back the survey results. The purpose of this study is to examine how, in a real-life scenario, a professional studio engineer can produce the best results using the best plugins, effects, and tools available in GarageBand on iOS and Logic Pro X environment, and how these two results are comparatively perceived by both the general audience and professional audio experts.","['Wu, Jiayue Cecilia', 'Das, Orchisama', 'DiPasquale, Vincent']","['University of Colorado Denver, Denver, CO, USA', 'Center for Computer Research in Music and Acoustics (CRMA), Stanford University, Stanford, CA, USA']",Recording and Production,Poster
15,Sound Capture by Microphone Vibration inside Playback Devices,"Integration of voice capture into devices that formerly were used only as a sound source, or that now need to include the ability to interface with a variety of cloud-provided services available to users and/or expand voice control capability to otherwise simple devices has become commonplace, and integration of multiple microphones inside a case that houses playback transducers requires careful attention to certain design aspects as will be discussed in this article where a prototype of a ""Smart Speaker"" will be used as an example.","['De Oliveira, Rivanaldo']","['Qualcomm Technologies, Inc., San Diego, CA, USA']",Transducers,Talk
16,Alignment of Triple Chamber Eighth-Order Band-Pass Loudspeaker Systems,"An eighth-order band-pass loudspeaker system consisting of three vented chambers is analyzed. Since its frequency response has equal low-pass and high-pass cut-off slopes of fourth-order, the response function can be aligned to an eighth-order symmetric band-pass filter obtained by the frequency transformation method. For any desired frequency response, required system alignment parameters can be calculated by solving a system of equations. Design examples are presented and compared in terms of the mid-band attenuation factor and the diaphragm displacement.","['Dong, Hao', 'Shen, Yong', 'Chen, Rui']","['Nanjing University, Nanjing, China']",Transducers,Talk
17,Subjective Evaluation of Multichannel Audio and Stereo on Cell Phones,"With the increasing trend of using smart phones and other handheld electronic devices for accessing the internet, playback of audio in multichannel format would eventually gain popularity on such devices. Given the limited options for audio output on handheld electronic devices, it is important to know if multichannel audio offers an improvement in audio quality over other existing formats. This paper shows a subjective assessment test of multichannel audio versus stereo while played on a mobile phone using headphones. The results show that multichannel audio improves on perceived audio quality as compared to stereo.","['Toosy, Fesal', 'Ehsan, Muhammad Sarwar']","['University of Central Punjab, Lahore, Pakistan']",Perception,Poster
18,A Binaural Model to Estimate Room Impulse Responses from Running Signals and Recordings,"A binaural model is described that can use a multichannel signal to robustly localize a sound source in the presence of multiple reflections. The model also estimates a room impulse response from a running multichannel signal, e.g., from a recording, and determines the spatial locations and delays of early reflections, without any prior or additional knowledge of the source. A dual-layer cross-correlation/autocorrelation algorithm is used to determine the interaural time difference (ITD) of the direct sound source component and to estimate a binaural activity pattern. The model is able to accurately localize broadband signals in the presence of real room reflections.","['Braasch, Jonas', 'Dahlbom, David', 'Keil, Nate']","['Rensselear Polytechnic Institute, Troy, NY, USA']",Perception,Talk
19,Application of Modulated Musical Multitone Signal for Evaluation of Horn Driver Sound Quality,"This work introduces a new type of test signal called Modulated Musical Multitone (MMM): sinusoidal tones outlining E-minor triads in several octaves with amplitude modulation providing a variable crest factor which can match specific musical signals. Three different signals are used in the corresponding experiments including MMM, sinusoidal sweep, and music. An evaluation of sound quality is conducted for an FIR-filtered single horn driver. The effect of masking is observed when a matching linear low-pass channel is added to the signal. The multitone response is post-processed to obtain the distortion products spectrum.","['Voishvillo, Alexander', 'Kákonyi, Balázs', 'McLaughlin, Brian']","['Harman Professional Solutions, Northridge, CA, USA']",Transducers,Talk
20,Use of DNN-Based Beamforming Applied to Different Microphone Array Configurations,"Minimum variance distortionless response (MVDR) beamforming is one of the most popular multichannel signal processing techniques for dereverberation and/or noise reduction. However, the MVDR beamformer has the limitation that it must be designed to be dependent on the receiver array geometry. This paper demonstrates an experimental setup and results by designing a deep learning-based MVDR beamformer and applying it to different microphone array configurations. Consequently, it is shown that the deep learning-based MVDR beamformer provides more robust performance under mismatched microphone array configurations than the conventional statistical MVDR one.","['Kim, Tae Woo', 'Kim, Nam Kyun', 'Lee, Geon Woo', 'Park, Inyoung', 'Kim, Hong Kook']","['Gwangju Institute of Science and Technology (GIST), Gwangju, South Korea']",Audio Signal Processing,Poster
21,Accurate Reproduction of Binaural Recordings through Individual Headphone Equalization and Time Domain Crosstalk Cancellation,"We have developed software apps that allow a user to non-invasively match headphones to reproduce the identical spectrum at the eardrum as that from a frontal source. The result is correct timbre and forward localization without head tracking. In addition we have developed a non-individual crosstalk cancelling algorithm that creates virtual sound sources just outside a listener’s ears. Both systems reproduce binaural recordings with startling realism. The apps enable researchers and students to hear what acoustical features are essential for clarity, proximity, and preference. Listening to any type of music with our apps is beautiful and highly engaging.","['Griesinger, David']","['David Griesinger Acoustics, Cambridge, MA, USA']",Room Acoustics,Talk
22,Investigation of Masking Thresholds for Spatially Distributed Sound Sources,"For perceptual audio coding of immersive content, the investigation of masking effects between spatially distributed sound sources is of interest. We conducted subjective listening experiments to determine the masking thresholds for “tone-masking-noise” conditions when masker (1 kHz sine tone) and probe (1 kHz narrow band noise) are spatially distributed using an immersive 22.2 loudspeaker setup. Our results show masking thresholds in the range of –35 dB to –26 dB probe-to-masker-ratio. As expected, least masking was found between left/right opposed sources with up to 5 dB lower than for coincident sources. Other noteworthy observations included an increase of masking for certain elevations and cases of selective masking decrease due to interaural phase difference phenomena.","['Dick, Sascha', 'Sweidan, Rami', 'Herre, Jürgen']","['International Audio Laboratories Erlangen, a joint institution of Universität Erlangen-Nürnberg and Fraunhofer IIS, Erlangen, Germany', 'Fraunhofer Institute for Integrated Circuits IIS, Erlangen, Germany', 'University of Stuttgart, Stuttgart, Germany']",Perception,Talk
23,The Effects of Spectators on the Speech Intelligibility Performance of Sound Systems in Stadia and Other Large Venues,"Stadiums and similar venues in the UK and throughout most of Europe are subject to strict safety standards and regulations, including the performance of their Public Address systems. The usual requirement is for the PA system to achieve a potential speech intelligibility performance of 0.50 STI, though some authorities and organizations require a higher value than this. However, a problem exists with measuring the performance of the system, as this can only be carried out in the empty stadium. The paper shows that with occupancy, the acoustic conditions change significantly, as the spectators introduce significant sound absorption and also increase the background noise level. The effect this can have on the intelligibility performance of the sound system is examined and discussed. The relationship between the unoccupied starting conditions and audience absorption and distribution are also investigated.","['Mapp, Peter', 'Hammond, Ross']","['Peter Mapp Associates, Colchester, Essex, UK', 'University of Derby, Derby, Derbyshire, UK']","Recording, Production, and Live Sound",Talk
24,A Dataset of High-Quality Object-Based Productions,"Object-based audio is an emerging paradigm for representing audio content. However, the limited availability of high-quality object-based content and the need for usable production and reproduction tools impede the exploration and evaluation of object-based audio. This engineering brief introduces the S3A object-based production dataset. It comprises a set of object-based scenes as projects for the Reaper digital audio workstation (DAW). They are accompanied by a set of open-source DAW plugins–—the VISR Production Suite—–for creating and reproducing object-based audio. In combination, these resources provide a practical way to experiment with object-based audio and facilitate loudspeaker and headphone reproduction. The dataset is provided to enable a larger audience to experience object-based audio, for use in perceptual experiments, and for audio system evaluation.","['Costantini, Giacomo', 'Franck, Andreas', 'Pike, Chris', 'Francombe, Jon', 'Woodcock, James', 'Hughes, Richard J.', 'Coleman, Philip', 'Whitmore, Eloise', 'Fazi, Filippo Maria']","['University of Southampton, Southampton, UK', 'BBC R&D, Salford, UK', 'University of Salford, Salford, UK', 'University of Surrey, Guildford, Surrey, UK', 'Naked Productions, Manchester, UK']",Recording and Production,Poster
25,Perceptual Weighting to Improve Coding of Harmonic Signals,"This paper describes a new approach to improving the coding of harmonic signals in transform-based audio codecs employing pulse vector quantization. The problem occurs when coding at low rate signals with varying levels of harmonics. As a result of vector quantization (VQ), some lower level harmonics may be missed or fluctuating and cause perceptual artifacts. The proposed solution consists of applying perceptual weighting to the computed synthesis error in the search loop of the VQ. The objective being to de-emphasize the error in the high tonal peaks where signal energy partially masks the quantization noise. Simulation results over mixed musical content showed a noticeable improvement in perceptual scores, particularly for highly harmonic signals.","['Nemer, Elias', 'Fejzo, Zoran', 'Thompson, Jeff']","['DTS/Xperi Corp., Calabasas, CA, USA']",Perception,Talk
26,Vibrary: A Consumer-Trainable Music Tagging Utility,"We present the engineering underlying a consumer application to help music industry professionals find audio clips and samples of personal interest within their large audio libraries typically consisting of heterogeneously-labeled clips supplied by various vendors. We enable users to train an indexing system using their own custom tags (e.g., instruments, genres, moods), by means of convolutional neural networks operating on spectrograms. Since the intended users are not data scientists and may not possess the required computational resources (i.e., Graphics Processing Units, GPUs), our primary contributions consist of (i) designing an intuitive user experience for a local client application to help users create representative spectrogram datasets, and (ii) ""seamless"" integration with a cloud-based GPU server for efficient neural network training.","['Hawley, Scott', 'Bagley, Jason', 'Porter, Brett', 'Traynham, Daisey']","['Belmont University, Nashville, TN, USA', 'Art+Logic, Pasadena, CA, USA', 'Art+Logic, Fanwood, NJ, USA']",Applications in Audio,Talk
27,Infinite Waveguide Termination by Series Solution in Finite Element Analysis,"The acoustics of an audio system may comprise of several components, e.g., a compression driver producing plane waves, a transition connecting to the throat of a horn, and a cylindrical horn which is baffled at the mouth. While finite elements/boundary elements can model the entire system, it is advantageous from the design perspective to consider simplified systems. A compression driver might be used in many situations and should be designed radiating plane waves, without cross modes, into a semi-infinite tube. The pressure field in the tube can be represented by a series that is coupled to the finite element mesh by a DtN approach. The method is generalized to cater for ducts of arbitrary cross section and infinite cylindrical horns.","['Macey, Patrick']","['PACSYS Limited, Nottingham, UK']",Transducers,Poster
28,"Just Noticeable Difference for Dynamic Range Compression via ""Limiting"" of a Stereophonic Mix","This study focused on the ability of listeners to discern the presence of dynamic range compression (DRC) when applied to a stereo recording. Past studies have primarily focused on listener preferences for stereophonic master recordings with varying levels of DRC. A modified two-down one-up adaptive test presented subjects with an increasingly “limited” stereophonic mix to determine the 70.7% response threshold. Results of this study suggest that DRC settings considered “normal” in recorded music production may be imperceptible when playback levels are loudness-matched. Outcomes of this experiment indicate the use of so-called “limiting” for commercial purposes, such as signal chain control, may have no influence on perceived quality; whereas, uses for perceived aesthetic advantages should be reconsidered.","['Hickman, Christopher', 'Bulla, Wesley']","['Belmont University, Nashville, TN, USA']",Perception,Poster
29,Evaluating Listener Preference of Flat-Panel Loudspeakers,"Three flat-panel loudspeakers and two conventional loudspeakers were evaluated in a blind listening test. Two of the flat-panel loudspeakers used in the test were prototypes employing both array-based excitation methods and constrained viscoelastic damping to eliminate modal resonant peaks in the mechanical response of the vibrating surface. The remaining flat-panel speaker was a commercially available unit. A set of 21 listeners reported average preference ratings of 7.00/10 and 6.81/10 for the conventional loudspeakers, 6.48/10 and 5.90/10 for the prototype flat-panel loudspeakers, and 2.24/10 for the commercial flat-panel speaker. The results are consistent with those given by a predictive model for listener preference rating, suggesting that designs aimed at smoothing the mechanical response of the panel lead to improved preference ratings.","['Roessner, Stephen', 'Heilemann, Michael', 'Bocko, Mark F.']","['University of Rochester, Rochester, NY, USA']",Transducers,Poster
30,Line Array Optimization through Innovative Multichannel Filtering,"Element dependent filtering offers the possibility to optimize the sound coverage of vertical line arrays: distance dependent frequency response, as well as mid-low frequency beaming and air absorption can be partially compensated. Simulation of array elements contributions to venue acoustics is normally the input data for filters calculation, but some phenomena exist in the real world that are hardly addressed by simulations: for example, the dispersion of transducers responses, as well as the acoustic paths atmospheric conditions, among different array elements. This awareness induced us to develop an algorithm with the aim of being robust against these inaccuracies.","['Martignon, Paolo', 'Di Cola, Mario', 'Chisari, Letizia']","['Contralto Audio srl, Casoli, Italy']",Audio Signal Processing,Talk
31,Acoustic Metamaterials in Loudspeaker Systems Design,"Materials have been used to control waves propagation ever since, and optics is a prime example. In Loudspeaker Systems applications, there have also been approaches in the attempt of controlling waves by acoustic lenses. Metamaterials are artificial structures, typically periodic, composed of small meta-atoms that, in the bulk, behave like continuous material with unconventional effective properties without the constraints normally imposed by nature. This talk offers the opportunity to share what can be done with acoustic metamaterials in audio industry, especially in Loudspeaker Systems Design. The presentation brings back some approaches from the past that can be revisited using today’s technologies. Moreover, this talk shows some of the already developed technologies that employ these extremely innovative materials.","['Chisari, Letizia', 'Di Cola, Mario', 'Martignon, Paolo']","['Contralto Audio srl, Casoli, Italy']",Transducers,Talk
32,Evaluation of Spatial Audio Quality of the Synthesis of Binaural Room Impulse Responses for New Object Positions,"The aim of auditory augmented reality is to create an auditory illusion combining virtual audio objects and scenarios with the perceived real acoustic surrounding. A suitable system like position-dynamic binaural synthesis is needed to minimize perceptual conflicts with the perceived real world. The needed binaural room impulse responses (BRIRs) have to fit the acoustics of the listening room. One approach to minimize the large number of BRIRs for all source-receiver relations is the synthesis of BRIRs using only one measurement in the listening room. The focus of the paper is the evaluation of the spatial audio quality. In most conditions differences in direct-to-reverberant-energy ratio between a reference and the synthesis is below the just noticeable difference. Furthermore, small differences are found for perceived overall difference, distance, and direction perception. Perceived externalization is comparable to the usage of measured BRIRs. Challenges are detected to synthesize more further away sources from a source position that is more close to the listening positions.","['Werner, Stephan', 'Klein, Florian', 'Müller, Clemens']","['Technische Universität Ilmenau, Ilmenau, Germany']",Spatial Audio,Poster
33,An Open Audio Processing Platform Using SoC FPGAs and Model-Based Development,"The development cycle for high performance audio applications using System-on-Chip (SoC) Field Programmable Gate Arrays (FPGAs) is long and complex. To address these challenges, an open source audio processing platform based on SoC FPGAs is presented. Due to their inherently parallel nature, SoC FPGAs are ideal for low latency, high performance signal processing. However, these devices require a complex development process. To reduce this difficulty, we deploy a model-based hardware/software co-design methodology that increases productivity and accessibility for non-experts. A modular multi-effects processor was developed and demonstrated on our hardware platform. This demonstration shows how a design can be constructed and provides a framework for developing more complex audio designs that can be used on our platform.","['Vannoy, Trevor', 'Davis, Tyler', 'Dack, Connor', 'Sobrero, Dustin', 'Snider, Ross']","['Montana State University, Bozeman, MT, USA', 'Flat Earth Inc., Bozeman, MT, USA']",Audio Signal Processing,Poster
34,A Case Study of Cultural Influences on Mixing Preference—Targeting Japanese Acoustic Major Students,"There is no clear rule in the process of mixing in popular music production, so even with the same music materials, different mix engineers may arrive at a completely different mix. In order to solve this highly multidimensional problem, some listening experiments of mixing preference have been conducted in Europe and North America in previous studies. In this study additional experiments targeting Japanese major students in the field of acoustics were conducted in an acoustically treated listening room, and we integrated the data with previous ones and analyzed them together. The result showed a tendency for both British students and Japanese students to prefer (or dislike) the same engineers’ works. Furthermore, an analysis of verbal descriptions for mixing revealed that they gave most attention to similar listening points, such as “vocal,” and “reverb.”","['Tajima, Toshiki', 'Kawahara, Kazuhiko']","['Kyushu University, Fukuoka, Japan']",Recording and Production,Poster
35,An Attempt to Elicit Horizontal and Vertical Auditory Precedence Percepts without Pinnae Cues,"This investigation was a continuation of AES-143 paper #9832 and AES-145 paper #10066 where reliable auditory precedence in the elevated, ear-level, and lowered horizontal planes was examined. This experiment altered and eliminated the spectral influences that govern the detection of elevation and presented two different horizontal and vertical inter-channel time delays during a precedence-suppression task. A robust precedence effect was elicited via ear-level horizontal plane loudspeakers. In contrast, leading signal identification was minimal in the vertical condition and no systematic influence of the leading elevated and lowered median plane loudspeakers was witnessed suggesting that precedence was not active in the vertical condition. Observed influences that might have been generated by the lead-lag signal in the vertical plane was not consistent with any known precedence paradigms.","['Bulla, Wesley', 'Mayo, Paul']","['Belmont University, Nashville, TN, USA', 'University of Maryland, College Park, MD, USA']",Perception,Talk
36,Measuring Speech Intelligibility Using Head-Oriented Binaural Room Impulse Responses,"Speech intelligibility/speech clarity is important in any setting in which information is verbally communicated. More specifically, a high level of speech intelligibility is crucial in classrooms to allow teachers to effectively communicate with their students. Given the importance of speech intelligibility in learning environments, several studies have analyzed how accurately the standard method of measuring clarity predicts the level of speech intelligibility in a room. In the context of speech measurements, C50 has been widely used to measure clarity. Instead of using a standard omnidirectional microphone to record room impulse responses for clarity measurements, this study examines the effectiveness of room impulse responses measured with a binaural dummy head. The data collected for this experiment show that C50 measurements differ between the left and right channels by varying amounts based on the dummy head’s position in the room and head orientation. To further investigate the effectiveness of binaural C50 measurements in comparison to the effectiveness of omnidirectional C50 measurements, this research explores the results of psychoacoustic testing to determine which recording method more consistently predicts human speech intelligibility. These results, combined with qualitative observations, predict how precisely acousticians are able to measure C50.","['Lam, Allison', 'Lee, Ming-Lun', 'Philbert, Steve']","['Tufts University, Medford, MA, USA', 'University of Rochester, Rochester, NY, USA']",Applications in Audio,Poster
37,Realizing an Acoustic Vector Network Analyzer,"Acoustic absorption, reflection, and transmission is typically measured using an impedance tube. We present the design and initial measurements of a radically different measurement system. The instrument builds on the rich history and deep mathematics developed in pursuit of electromagnetic Vector-corrected Network Analyzers (VNAs). Using acoustic directional couplers and a traditional VNA mainframe we assembled an “Acoustic Vector Network Analyzer” (AVNA). The instrument measures acoustic scattering parameters, the complex reflection and transmission coefficients, of materials, transmission lines, ported structures, ducts, etc. After the fashion of electromagnetic VNAs we have constructed millimeter-wave measurement heads that span the 800 Hz–2200 Hz (420–150 mm) and 10 kHz–22 kHz (35–15 mm) bands, demonstrating scalability. We present initial measurement results.","['MacDonell, Marcus', 'Scott, Jonathan']","['University of Waikato, Hamilton, Waikato, New Zealand']",Applications in Audio,Talk
38,Sound Design and Reproduction Techniques for Co-Located Narrative VR Experiences,"Immersive co-located theatre aims to bring the social aspects of traditional cinematic and theatrical experience into Virtual Reality (VR). Within these VR environments, participants can see and hear each other, while their virtual seating location corresponds to their actual position in the physical space. These elements create a realistic sense of presence and communication, which enables an audience to create a cognitive impression of a shared virtual space. This article presents a theoretical framework behind the design principles, challenges and factors involved in the sound production of co-located VR cinematic productions, followed by a case-study discussion examining the implementation of an example system for a 6-minute cinematic experience for 30 simultaneous users. A hybrid reproduction system is proposed for the delivery of an effective sound design for shared cinematic VR. Winner of the 147th AES Convention Best Peer-Reviewed Paper Award","['Gospodarek, Marta', 'Genovese, Andrea', 'Dembeck, Dennis', 'Brenner, Corinne', 'Roginska, Agnieszka', 'Perlin, Ken']","['New York University, New York, NY, USA', 'Flavorlab']",Spatial Audio,Poster
39,Field Report: Immersive Recording of a Wind Ensemble Using Height Channels and Delay Compensation for a Realistic Playback Experience,"Practical examples for orchestra recording in stereo or surround were relatively easy to obtain. Whereas, it was found that recording practice in immersive audio is relatively limited. This paper is intended to share the experience of the immersive recording process for a wind orchestra recording at McGill University. There were concerns that needed to be considered before planning the concert recording, problems encountered during the planning, and lastly the solutions to these issues. In conclusion, the discussions about the final result and the approach will be described.","['Yang, Hyunjoung', 'Dobson, Alexander', 'King, Richard']","['McGill University, Montréal, QC, Canada', 'The Centre for Interdisciplinary Research in Music Media and Technology, Montreal, Quebec, Canada']",Spatial Audio,Poster
40,Deep Neural Network Based Guided Speech Bandwidth Extension,"Up to today telephone speech is still limited to the range of 200 to 3400 Hz since the predominant codecs in public switched telephone networks are AMR-NB, G.711, and G.722 [1, 2, 3]. Blind bandwidth extension (blind BWE, BBWE) can improve the perceived quality as well as the intelligibility of coded speech without changing the transmission network or the speech codec. The BBWE used in this work is based on deep neural networks (DNNs) and has already shown good performance [4]. Although this BBWE enhances the speech without producing too many artifacts it sometimes fails to enhance prominent fricatives that can result in muffled speech. In order to better synthesize prominent fricatives the BBWE is extended by sending a single bit of side information—here referred to as guided BWE. This bit may be transmitted, e.g., by watermarking so that no changes to the transmission network or the speech codec have to be done. Different DNN con?gurations (including convolutional (Conv.) layers as well as long short-term memory layers (LSTM)) making use of this bit have been evaluated. The BBWE has a low computational complexity and an algorithmic delay of 12 ms only and can be applied in state-of-the-art speech and audio codecs.","['Schmidt, Konstantin', 'Edler, Bernd']","['Friedrich Alexander University, Erlangen-Nürnberg, Germany', 'Fraunhofer IIS, Erlangen, Germany']",Audio Signal Processing,Poster
41,Physical Controllers vs. Hand-and-Gesture Tracking: Control Scheme Evaluation for VR Audio Mixing,"This paper investigates potential differences in performance for both physical and hand-and-gesture control within a Virtual Reality (VR) audio mixing environment. The test was designed to draw upon prior evaluations of control schemes for audio mixing while presenting sound sources to the user for both controller schemes within VR. A VR audio mixing interface was developed in order to facilitate a subjective evaluation of two control schemes. Response data was analyzed with t- and ANOVA tests. Physical controllers were generally rated higher than the hand-and-gesture controls in terms of perceived accuracy, efficiency, and satisfaction. No significant difference in task completion time for either control scheme was found. The test participants largely preferred the physical controllers over the hand-and-gesture control scheme. There were no significant differences in the ability to make adjustments in general when comparing groups of more experienced and less experienced audio engineers.","['Bennington, Justin', 'Ko, Doyuen']","['Belmont University, Nashville, TN, USA']","Spatial Audio, Part 2",Talk
42,The Application of Graphene Oxide-Based Loudspeaker Membranes in 40mm Headphone Drivers,"Graphene oxide-based materials have shown promise in loudspeaker membrane applications. The material allows the forming of highly stiff, low mass cones and domes for loudspeakers. The technology allows improvements in efficiency and linearity over other common loudspeaker membrane materials. This class of graphene material can be engineered to produce an excellent ratio of stiffness (Young’s modulus) to density (g/cm3) and damping (tan ? ). In a case study, acoustically optimized graphene materials were formed into membranes for headphone drivers. The performance of headphone drivers made with these membranes was analyzed and compared to standard polymer membrane headphone drivers. Relative to the polymer membrane drivers, the graphene membranes provide a significant reduction in both intermodulation and harmonic distortion while matching the sensitivity and producing a substantially smoother frequency response.","['Cardenas, William', 'Gaskell, Robert-Eric']","['ORA Graphine Audio Inc., Montreal, Quebec, Canada', 'McGill University, Montreal, QC, Canada']",Transducers,Talk
43,Impact of Statistical Parameters of Late Reverberation on the Instantaneous Frequencies of Reverberant Audio,"This paper addresses the impact of late reverberation on the instantaneous frequency tracks of reverberant audio. While existing models of early reflections and low frequency room modes enable prediction of instantaneous frequency tracks of a filtered signal, the effects of late reverberation are best modeled statistically. After reviewing the parameterization of late reverberation, the effects of frequency dependent decay time and direct to reverberant ratio on instantaneous frequency are investigated using synthetic impulse responses derived from velvet noise. These effects are quantified using the autocorrelation function of the reverberant instantaneous frequency tracks. Finally, the instantaneous frequency deviations that occur when an anechoic sound is filtered with a recorded impulse response are compared to those resulting from synthesized late reverberation.","['Smith, Sarah R.', 'Bocko, Mark F.']","['University of Rochester, Rochester, NY, USA']",Semantic Audio,Talk
44,Calculation of Directivity Patterns from Spherical Microphone Array Recordings,"Taking into account the direction-dependent radiation of natural sound sources (such as musical instruments) can help to enhance auralization processing and thus improves the plausibility of simulated acoustical environments as, e.g., found in virtual reality (VR) systems. In order to quantify this direction-dependent behavior, usually so-called directivity patterns are used. This paper investigates two different methods that can be used to calculate directivity patterns from spherical microphone array recordings. A comparison between both calculation methods is performed based on the resulting directivity patterns. Furthermore, the directivity patterns of several musical instruments are analyzed and important measures are extracted. For all calculations, the publicly available anechoic microphone array measurements database recorded at the Technical University Berlin (TU Berlin) was used.","['Anemüller, Carlotta', 'Herre, Jürgen']","['International Audio Laboratories Erlangen, Erlangen, Germany', 'Fraunhofer IIS, Erlangen, Germany']",Room Acoustics,Poster
45,The 3DCC Microphone Technique: A Native B-format Approach to Recording Musical Performance,"In this paper we propose a “native” B-format recording technique that uses dual-capsule microphone technology. The three dual coincident capsule (3DCC) microphone array is a compact sound?eld capturing system. 3DCC’s advantage is that it requires minimal matrix processing during post-production to create either a B-format signal or a multi-pattern, discrete six-channel output with high stereo compatibility. Given its versatility, the system is also capable of producing a number of different primary and secondary signals that are either natively available or derived in post-production. A case study of the system’s matrixing technique has resulted in robust immersive imaging in a multichannel listening environment, leading to the possibility of future development of the system as a single six-channel soundfield microphone.","['Zhang, Kathleen ""Ying-Ying""', 'Geluso, Paul']","['New York University, New York, NY, USA']","Spatial Audio, Part 3",Talk
46,Nonlinear Control of Loudspeaker Based on Output Flatness and Trajectory Planning,"A loudspeaker is inherently nonlinear and produces timbre alterations, roughness, harshness, lack of clarity, and modulation noise. This may impair reproduction quality and speech intelligibility. These issues increase rapidly with high levels and especially high bass levels. Industrial design and marketing constraints demand smaller speaker systems without sacrificing sound output level. This results in higher distortion. To obtain ""big bass from little boxes,"" an anti-distortion system is needed. We present a new approach that is based on the direct control and linearization of the loudspeaker diaphragm displacement that allows the maximization of the bass output and the minimization of the nonlinearities while keeping the diaphragm displacement within the range of safe operation.","['Brunet, Pascal', 'Kubota, Glenn S.']","['Samsung Research America, Valencia, CA USA']",Transducers,Talk
47,Tetra-Speaker: Continual Evaluation of the Immersive Experience of a Single-Point Reproduction System,"In the first phase of experimentation, a tetra-speaker had been built as an efficient and compact system for the reproduction of individual sound sources. The reproduction process was based on the relationship of a single sound source, such as an instrument, and an acoustic space. This relationship focused on the radiating behavior of the source. In this paper the tetra-speaker is further evaluated in a case-like study on the immersive experience of the system with additional discussion of how the system may expand its usage to improve this experience within virtual environments. Professionals within the audio field were asked to give an expert’s opinion based on defined attributes of spatial impression and realism.","['Songmuang, Parichat']","['New York University, New York, NY, USA']",Spatial Audio,Talk
48,Profiling Audio Compressors with Deep Neural Networks,"We present a data-driven approach for predicting the behavior of (i.e., profiling) a given parameterized, non-linear time-dependent audio signal processing effect. Our objective is to learn a mapping function that maps the unprocessed audio to the processed, using time-domain samples. We employ a deep auto-encoder model that is conditioned on both time-domain samples and the control parameters of the target audio effect. As a test-case, we focus on the offline profiling of two dynamic range compressors, one software-based and the other analog. Our results show that the primary characteristics of the compressors can be captured, however there is still sufficient audible noise to merit further investigation before such methods are applied to real-world audio processing workflows.","['Hawley, Scott', 'Colburn, Benjamin', 'Mimilakis, Stylianos Ioannis']","['Belmont University, Nashville, TN, USA', 'ARiA Acoustics, Washington, DC, USA', 'Fraunhofer Institute for Digital Media Technology (IDMT), Ilmenau, Germany']",Audio Signal Processing,Talk
49,Modelling of a Chip Scale Package on the Acoustic Behavior of a MEMS Microphone,"Micro-electro-mechanical system (MEMS) microphones have been widely used in the mobile devices in recent decades. The acoustic effects of a chip scale package on a MEMS microphone needs to be validated. Previously a lumped equivalent circuit model was adopted to analyze the acoustic frequency response of the package. However, such a theoretical model cannot predict performance at relatively high frequencies. In this paper a distributed parameter model was proposed to simulate the acoustic behavior of the MEMS microphone package. The model illustrates how the MEMS microphone acoustic transfer function is affected by the size of sound hole, the volumes of the front and back chamber. This model also can illustrate the mechanical response of the MEMS microphone. The proposed model provided a more reliable way towards an optimized MEMS package structure.","['Nie, Yafei', 'Sang, Jinqiu', 'Zheng, Chengshi', 'Li, Xiaodong']","['Institute of Acoustics, Chinese Academy of Sciences, Beijing, China', 'Chinese Academy of Sciences, Beijing, China']",Transducers,Poster
50,Use of the Magnitude Estimation Technique in Reference-Free Assessments of Spatial Audio Technology,"Magnitude estimation is a technique developed in psychophysics research in which participants numerically estimate the relative strengths of a sequence of stimuli along a relevant dimension. Traditionally, the method has been used to measure basic perceptual phenomena in different sensory modalities (e.g., ""brightness,"" ""loudness""). We present two examples of using magnitude estimation in the domain of audio rendering for different categories of consumer electronics devices. Importantly, magnitude estimation doesn’t require a reference stimulus and can be used to assess general (""audio quality"") and domain-specific (e.g., ""spaciousness"") attributes. Additionally, we show how this data can be used together with objective measurements of the tested systems in a model that can predict performance of systems not included in the original assessment.","['Brandmeyer, Alex', 'Darcy, Dan', 'Lu, Lie', 'Graff, Richard', 'Swedlow, Nathan', 'Crum, Poppy']","['Dolby Laboratories, San Francisco, CA, USA']","Spatial Audio, Part 1",Talk
51,An Adaptive Crosstalk Cancellation System Using Microphones at the Ears,"For the reproduction of binaural signals via loudspeakers, crosstalk cancellation systems are necessary. To compute the crosstalk cancellation filters, the transfer functions between loudspeakers and ears must be given. If the listener moves the filters are usually updated based on a model or previously measured transfer functions. We propose a novel architecture: It is suggested to place microphones close to the listener’s ears to continuously estimate the true transfer functions and use those to adapt the crosstalk cancellation filters. A fast frequency-domain state-space approach is employed for multichannel system tracking. For simulations of slow listener rotations it is demonstrated by objective and subjective means that the proposed system successfully attenuates crosstalk of the direct sound components.","['Kabzinski, Tobias', 'Jax, Peter']","['RWTH Aachen University, Aachen, Germany']",Spatial Audio,Poster
52,A Compact Loudspeaker Matrix System to Create 3D Sounds for Personal Uses,"In this paper we propose a new 3D sound system in two-layers as a matrix that has five loudspeakers on each side of the listener. The system is effective for sound localization and compact for personal use. Sound images in this system are created by extended amplitude panning method, with the effect of head-related transfer functions (HRTFs). Performance evaluation of the system for sound localization was made by auditory experiments with listeners. As the result, listeners could distinguish sound image direction localized at any azimuth direction and high elevation direction with small biases.","['Saito, Aya', 'Nemoto, Takahiro', 'Saji, Akira', 'Huang, Jie']","['University of Aizu, Aizuwakamatsu City, Japan']",Spatial Audio,Poster
53,An Open-Access Database of 3D Microphone Array Recordings,"This engineering brief presents open-access 3D sound recordings of musical performances and room impulse responses made using various 3D microphone arrays simultaneously. The microphone arrays comprised OCT-3D, 2L-Cube, PCMA-3D, Decca Tree with height, Hamasaki Square with height, First-order and Higher-order Ambisonics microphone systems, providing more than 250 different front-rear-height combinations. The sound sources recorded were string quartet, piano trio, piano solo, organ, clarinet solo, vocal group, and room impulse responses of a virtual ensemble with 13 source positions captured by all of the microphones. The recordings can be freely downloaded from www.hud.ac.uk/apl/resources. Future studies will use the recordings to formally elicit perceived attributes for 3D recording quality evaluation as well as for spatial audio ear training.","['Lee, Hyunkook', 'Johnson, Dale']","['University of Huddersfield, Huddersfield, UK']",Recording and Production,Poster
54,Filling The Space: The Impact of Convolution Reverberation Time on Note Duration and Velocity in Duet Performance,"The impact of reverberation on musical expressivity is an area of growing interest as technology to simulate, and create, acoustic environments improves. Being able to characterize the impact of acoustic environments on musical performance is a problem of interest to acousticians, designers of virtual environments, and algorithmic composers. We analyze the impact of convolution reverberation time on note duration and note velocity, which serve as markers of musical expressivity. To improve note clarity in situations of long reverberation times, we posit musicians performing in a duo would lengthen the separation between notes (note duration) and increase loudness (note velocity) contrast. The data for this study comprises of MIDI messages extracted from performances by 2 co-located pianists playing the same piece of music 100 times across 5 different reverberation conditions. To our knowledge, this is the largest data set to date looking at piano duo performance in a range of reverberation conditions. In contrast to prior work the analysis considers both the entire performance as well as an excerpt at the opening part of the piece featuring a key structural element of the score. This analysis ?nds convolution reverberation time is found to be moderately positively correlated with mean note duration (r = 0.34 and p =< 0.001), but no significant correlation was found between convolution reverberation time and mean note velocity (r = -0.19 and p = 0.058).","['Weaver, James', 'Barthet, Mathieu', 'Chew, Elaine']","['Queen Mary University London, London, UK', 'CNRS-UMR9912/STMS (IRCAM), Paris, France']","Recording, Production, and Live Sound",Talk
55,A Perceptually-Motivated Headphone Transparency Algorithm,"Many modern closed-back wireless headphones now support a user-selectable “hear-through” or “transparency” feature to allow the wearer to monitor their environment. These products typically work by passively mixing the signals from external microphones with the primary media being reproduced by the headphone’s internal speakers. When there is no media playing back, that approach works reasonably well. However, once media is playing, it tends to mask the passthrough of the external audio and the wearer can no longer hear the outside world. Here we describe a perceptually motivated algorithm for improving audibility of the external microphone signals without compromising the media playback experience. Subjective test results of this algorithm as implemented in a consumer headphone product are presented.","['Lando, Josh', 'Brandmeyer, Alex', 'Brown, Phil', 'Seefeldt, Alan', 'Jaspar, Andy']","['Dolby Laboratories, San Francisco, CA, USA']",Product Development,Talk
56,A Case Study on a Dynamic Driver: How Electromagnet Can Improve the Performance of a Micro Speaker,"How can designers improve the sound quality of next-generation audio products when the market is demanding smaller devices? Bigger sound requires bigger speakers, right? Not necessarily. One approach is to re-evaluate the materials you are using. Alloy materials used within speakers to conduct sound has not changed drastically in the last 10-15 years. However, developments in the performance of electromagnet alloys can replace standard electrical iron/low carbon steel and provide higher efficiency and performance. The result is better sound quality, smaller devices, and extended battery life. We studied the performance of the transducer with different electromagnets in magnet assembly and reported the comparison to provide better insight for the next-gen audio dynamic drives.","['Mehedi, Md']","['Carpenter Technology Corporation, Philadelphia, PA, USA']",Transducers,Talk
57,Analysis of the Sound Emitted by Honey Bees in a Beehive,"The increasing in honey bee mortality of the last years has brought great attention on the possibility of intensive bee hive monitoring in order to better understand the problems that are seriously affecting the honey bee health. It is well known that sound emitted inside a beehive is one of the key parameters for a non-invasive monitoring capable of determining some aspects of their condition. The proposed work aims at analyzing the bees’ sound introducing features extraction useful for sound classification techniques and to determine dangerous situations. Taking into consideration a real scenario, several experiments have been performed focusing on particular events, such as swarming, to highlight the potentiality of the proposed approach.","['Cecchi, Stefania', 'Terenzi, Alessandro', 'Orcioni, Simone', 'Piazza, Francesco']","['Universitá Politecnica della Marche, Ancona, Italy']",Audio Signal Processing,Poster
58,Measurement of Oral-Binaural Room Impulse Response by Singing Scales,"Oral-binaural room impulse responses (OBRIRs) are the transfer functions from mouth to ears measured in a room. Modulated by many factors, OBRIRs contain information for the study of stage acoustics from the performer’s perspective and can be used for auralization. Measuring OBRIRs on a human is, however, a cumbersome and time-consuming process. In the current study some issues of the OBRIR measurement on humans were addressed in a series of measurements. With in-ear and mouth microphones volunteers sang scales, and a simple post-processing scheme was used to re?ne the transfer functions. The results suggest that OBRIRs may be measured consistently by using the proposed protocol, where only 4~8 diatonic scales need to be sung depending on the target signal-to-noise ratio.","['Park, Munhum']","['King Mongkut’s Institute of Technology Ladkrabang, Bangkok, Thailand']","Spatial Audio, Part 3",Talk
59,Loudspeaker Port Design for Optimal Performance and Listening Experience,"Bass reflex ports produce noise at high sound-pressure levels due to turbulence and vortex shedding. Flared ports can reduce port noise compared to straight ports, but the optimal flare rate in ports has remained an unsolved problem. This work demonstrates that there is in fact an optimal amount of flare, and it proposes a design method based on acoustic Finite Element simulations to efficiently predict the optimal flare rate for given port dimensions. Optimality of the flare rate is confirmed with noise and compression measurements as well as double-blind listening tests. At onset of unwanted port noise, optimally flared ports can be played 1 to 3 dB louder than slightly under-flared or over-flared ports, and 10 to 16 dB louder than straight ports.","['Bezzola, Andri', 'Devantier, Allan', 'McMullin, Elisabeth']","['Samsung Research America, Valencia, CA USA']",Product Development,Talk
60,Rethinking Flat Panel Loudspeakers—An Objective Acoustic Comparison of Different Speaker Categories,"The home entertainment market is growing, but connected devices like multi-room and streaming loudspeakers are increasingly replacing traditional audio systems. Compromises in the acoustic quality are made to satisfy additional requirements such as smaller, lighter, and cheaper products. The number of smart speakers sold suggests that the customers accept speakers with lower acoustical quality for their daily use. Concepts like soundbars aim to achieve better spatial reproduction but try to stay visually unobtrusive. Thanks to the low visual profile flat panel loudspeakers give opportunities for invisible integration. This paper presents an objective acoustic comparison of four speaker categories: smart speaker, flat panel, soundbar, and studio monitor. The comparison reveals that recent technological advances could make flat panel loudspeakers an alternative.","['Zenker, Benjamin', 'Merchel, Sebastian', 'Altinsoy, M. Ercan']","['Technical University Dresden, Dresden, Germany']",Transducers,Talk
61,A Comparison of Test Methodologies to Personalize Headphone Sound Quality,"There exist many different methods to gather subjective equalization preference data from listeners. From one method to another there are generally tradeoffs between speed, accuracy, and ease of use. In this study four different types of test were compared to see which tests performed the best in each of these categories. The purpose was to select the best methods for headphone personalization applications for mobile devices. All four tests involve test subjects setting filter gain values for bass and treble shelving filters, and thus selecting their preferred response curves for listening to music through headphones. The results of each test, the time taken to complete them, and the ease of use based on a post-test questionnaire are presented.","['Welti, Todd', 'Khonsaripour, Omid', 'Olive, Sean', 'Pye, Dan']","['Harman International Inc., Northridge, CA, USA']",Transducers,Talk
62,Predicting Objective Difficulty in Peak Identification Task of Technical Ear Training,"Technical ear training is a method to improve the ability to focus on a speci?c sound attribute and to communicate using the vocabularies and units shared in Audio Engineering. In designing the successful course in a sound engineers’ educational institution, it is essential to have a gradual increase in the task dif?culty. In this e-Brief, the authors investigated creating a predictive model of objective dif?culty for a given music excerpt when it is used in a peak identi?cation task of technical ear training. The models consisting of six or seven acoustic features, including statistics on attack transients and power spectrum, showed overall better results.","['Marui, Atsushi', 'Kamekawa, Toru']","['Tokyo University of the Arts, Adachi-ku, Tokyo, Japan']",Recording and Production,Talk
63,Alignment and Timeline Construction for Incomplete Analogue Audience Recordings of Historical Live Music Concerts,"Analogue recordings pose specific problems during automatic alignment, such as distortion due to physical degradation, or differences in tape speed during recording, copying, and digitization. Oftentimes, recordings are incomplete, exhibiting gaps with different lengths. In this paper we propose a method to align multiple digitized analogue recordings of same concerts of varying quality and song segmentations. The process includes the automatic construction of a reference concert timeline. We evaluate alignment methods on a synthetic dataset and apply our algorithm to real-world data.","['Wilmering, Thomas', 'Thalmann, Florian', 'Sandler, Mark']","['Centre for Digital Music (C4DM), Queen Mary University of London, London, UK']",Applications in Audio,Poster
64,Casualty Accessible and Enhanced (A&E) Audio: Trialling Object-Based Accessible TV Audio,"Casualty Accessible and Enhanced (A&E) Audio is the first public trial of accessible audio technology using a narrative importance approach. This trial allows viewers to personalize the audio of an episode of the BBC’s ""Casualty"" drama series based on their hearing needs. Using a simple interface the audio can be varied between the broadcast mix and an accessible mix containing narratively important non-speech sounds, enhanced dialogue, and attenuated background sounds. This paper describes the trial’s development, implementation, and it’s evaluation by normal and hard of hearing listeners (n=5209 on 20/8/2019). 299 participants also completed a survey, rating the technology 3.6/5 stars. 73% reported the technology made the content more enjoyable or easier to understand.","['Ward, Lauren', 'Paradis, Matthew', 'Shirley, Ben', 'Russon, Laura', 'Moore, Robin', 'Davies, Rhys']","['University of Salford, Salford, UK', 'BBC R&D, Salford, UK', 'BBC Research and Development, London, UK', 'BBC Studios, Cardiff, Wales, UK']",Applications in Audio,Talk
65,Exploratory Research into the Suitability of Various 3D Input Devices for an Immersive Mixing Task,"This study evaluates the suitability of one 2D (mouse and fader) and three 3D (Leap Motion, Space Mouse, Novint Falcon) input devices for an immersive mixing task. A test, in which subjects were asked to pan a monophonic sound object (probe) to the location of a pink noise burst (target), was conducted in a custom 3D loudspeaker array. The objectives were to determine how quickly the subjects were able to perform the task using each input device, which of the four was most appropriate for the task, and which was most preferred overall. Results show significant differences in response time between 2D and 3D input devices. Furthermore, it was found that localization blur had a significant influence over the subject’s response time, as well as “corner” locations.","['Quiroz Orozco, Diego I', 'Martin, Denis']","['McGill University, Montreal, QC, Canada', 'CIRMMT, Montreal, QC, Canada']","Spatial Audio, Part 3",Talk
66,A Qualitative Investigation of Soundbar Theory,"This study investigated basic acoustic principals and assumptions that form the foundation of soundbar technology. A qualitative listening test compared 12 original soundscape scenes each comprising five stationary and two moving auditory elements. Subjects listened to a 5.1 reference scene and were asked to rate “spectral clarity and richness of sound,” “width and height,” and “immersion and envelopment” of stereophonic, soundbar, and 5.1 versions of each scene. ANOVA revealed a significant effect for all three systems. In all three attribute groups, stereophonic was rated lowest, followed by soundbar, then surround. Results suggest waveguide-based “soundbar technology” might provide a more immersive experience than stereo but will not likely be as immersive as true surround reproduction.","['Perla, Julia', 'Bulla, Wesley']","['Belmont University, Nashville, TN, USA']",Spatial Audio,Poster
67,Evaluation on the Perceptual Influence of Floor Level Loudspeakers for Immersive Audio Reproduction,"Listening tests were conducted to evaluate the perceptual influence of adding a lower layer of loudspeakers to a setup that is commonly used for immersive audio reproduction. Three setups using horizontally arranged loudspeakers (1M, 2M, 5M), one with added height loudspeakers (5M+4H), and one with additional ?oor level loudspeakers (5M+4H+3L) were compared. Basic Audio Quality was evaluated in a sweet-spot test with explicit reference, and two preference tests (sweet-spot and off sweet-spot) were performed to evaluate the Overall Audio Quality. The stimuli, e.g., ambient recordings and sound design material, made dedicated use of the lower loudspeaker layer. The results show that reproduction comprising a lower loudspeaker layer is preferred compared to reproduction using the other loudspeaker setups included in the test.","['Grewe, Yannik', 'Walther, Andreas', 'Klapp, Julian']","['Fraunhofer Institute for Integrated Circuits IIS, Erlangen, Germany']","Spatial Audio, Part 1",Talk
68,Extracting the Fundamental Mode from Sound Pressure Measurements in an Acoustic Tube,Acoustic tubes are used to provide a load to loudspeakers or to measure material properties. If the wavelength is comparable to the diameter of the tube cross-modes can be excited. This paper demonstrates a method that allows to extract only the fundamental mode from the measurement of the sound-pressure response. The only requirement is the use of three microphones mounted into the sides of the tube-wall as well as a circular cross-section.,"['Panzer, Joerg']","['R&D Team, Salgen, Germany']",Room Acoustics,Talk
69,An HRTF Based Approach towards Binaural Sound Source Localization,"With the evolution of smart headphones, hearables, and hearing aids there is a need for technologies to improve situational awareness. The device needs to constantly monitor the real world events and cue the listener to stay aware of the outside world. In this paper we develop a technique to identify the exact location of the dominant sound source using the unique spectral and temporal features listener’s head-related transfer functions (HRTFs). Unlike most state-of-the-art beamforming technologies, this method localizes the sound source using just two microphones thereby reducing the cost and complexity of this technology. An experimental framework is setup at the EmbodyVR anechoic chamber, and hearing aid recordings are carried out for several different trajectories, SNRs, and turn-rates. Results indicate that the source localization algorithms perform well for dynamic moving sources for different SNR levels.","['Sunder, Kaushik', 'Wang, Yuxiang']","['Embody VR, Mountain View, CA, USA', 'University of Rochester, Rochester, NY, USA']","Spatial Audio, Part 2",Talk
70,Coherence as an Indicator of Distortion for Wide-Band Audio Signals such as M-Noise and Music,"M-Noise is a new scientifically derived test signal whose crest factor as a function of frequency is modeled after real music. M-Noise should be used with a complementary procedure for determining a loudspeaker’s maximum linear SPL. The M-Noise Procedure contains criteria for the maximum allowable change in coherence as well as frequency response. When the loudspeaker and microphone are positioned as prescribed by the procedure, reductions in coherence are expected to be caused by distortion. Although higher precision methods for measuring distortion exist, coherence has the advantage that it can be calculated for wide-band signals such as M-Noise as well as music. Examples will demonstrate the perceived audio quality associated with different amounts of distortion-induced coherence loss.","['van Veen, Merlijn', 'Schwenke, Roger']","['Meyer Sound Laboratories, Berkeley, CA, USA']",Audio Signal Processing,Talk
71,"The ANU School of Music Post-Production Suites: Design, Technology, Research, and Pedagogy","This engineering brief considers the design, construction, technological capacity, research, and pedagogical remit of two post-production suites built at the ANU School of Music. These suites were constructed simultaneously to the recording studio refurbishment, as detailed in AES e-Brief #397 (2017). This new e-Brief first considers the intention and purpose behind the splitting of a single, large control room into two separate, versatile post-production spaces. Secondly, the e-Brief focuses on design and construction, with consideration given to acoustic treatment, functionality, ergonomic workflow, and aesthetics. The e-Brief also focuses technological capacity and the benefits of built-in limitations. Finally, the post-production suites are considered in the broader context of both the research and pedagogical activities of the School.","['Bennett, Samantha', 'Barnes, Matt']","['Australian National University, Canberra, Australia']",Recording and Production,Poster
72,Modal Representations for Audio Deep Learning,"Deep learning models for both discriminative and generative tasks have a choice of domain representation. For audio, candidates are often raw waveform data, spectral data, transformed spectral data, or perceptual features. For deep learning tasks related to modal synthesizers or processors, we propose new, modal representations for data. We experiment with representations such as an N-hot binary vector of frequencies, or learning a set of modal filterbank coefficients directly. We use these representations discriminatively–classifying cymbal model based on samples–as well as generatively. An intentionally naive application of a basic modal representation to a CVAE designed for MNIST digit images quickly yielded results, which we found surprising given less prior success when using traditional representations like a spectrogram image. We discuss applications for Generative Adversarial Networks, towards creating a modal reverberator generator.","['Skare, Travis', 'Abel, Jonathan S.', 'Smith, III, Julius O.']","['CCRMA, Stanford University, Stanford, CA, USA']",Audio Signal Processing,Poster
73,SALTE Pt. 2: On the Design of the SALTE Audio Rendering Engine for Spatial Audio Listening Tests in VR,The dedicated audio rendering engine for conducting listening experiments using the SALTE (Spatial Audio Listening Test Environment) open-source virtual reality framework is presented. The renderer can be used for controlled playback of Ambisonic scenes (up to 7th order) over headphones and loudspeakers. Binaural-based Ambisonic rendering facilitates the use of custom HRIRs contained within separate WAV ?les or SOFA ?les as well as head tracking. All parameters of the audio rendering software can be controlled in real-time by the SALTE graphical user interface. This allows for perceptual evaluation of Ambisonic scenes and different decoding schemes using custom HRTFs.,"['Rudzki, Tomasz', 'Earnshaw, Chris', 'Murphy, Damian', 'Kearney, Gavin']","['University of York, York, UK']",Spatial Audio,Poster
74,Fast Time Domain Stereo Audio Source Separation Using Fractional Delay Filters,"Our goal is a system for the separation of two speakers during teleconferencing or for hearing aids. To be useful in real time, we want it to work online with as low delay as possible. Proposed approach works in time domain, using attenuation factors and fractional delays between microphone signals to minimize cross-talk, the principle of a fractional delay and sum beamformer. Compared to other approaches this has the advantage that we have lower computational complexity, no system delay and no musical noise like in frequency domain algorithms. We evaluate our approach on convolutive mixtures generated from speech signals taken from the TIMIT data-set using a room impulse response simulator.","['Golokolenko, Oleg', 'Schuller, Gerald']","['TU- Ilmenau, Ilmenau, Germany']",Audio Signal Processing,Talk
75,Defining Immersion: Literature Review and Implications for Research on Immersive Audiovisual Experiences,"The use of the term “immersion” to describe a multitude of varying experiences in the absence of a definitional consensus has obfuscated and diluted the term. This paper presents a non-exhaustive review of previous work on immersion on the basis of which a definition of immersion is proposed: a state of deep mental involvement in which the subject may experience disassociation from the awareness of the physical world due to a shift in their attentional state. This definition is used to contrast and differentiate interchangeably used terms such as presence and envelopment from immersion. Additionally, an overview of prevailing measurement techniques, implications for research on immersive audiovisual experiences, and avenues for future work are discussed briefly.","['Agrawal, Sarvesh', 'Simon, Adèle', 'Bech, Søren', 'Bærentsen, Klaus', 'Forchhammer, Søren']","['Bang & Olufsen a/s, Struer, Denmark', 'Technical University of Denmark', 'Aalborg University, Aalborg, Denmark', 'Aarhus University, Aarhus, Denmark']","Spatial Audio, Part 1",Talk
76,Comparison Study of Listeners' Perception of 5.1 and Dolby Atmos,"Surround sound reproduction has been a common technology in almost every theater room for several decades. In 2012 Dolby Laboratories, Inc. announced a new spatial 3D audio format – Dolby Atmos [1] that (due to its object-based rendering) pushes the possibilities of spatial reproduction and supposedly listeners’ experience forward. This paper examines listeners’ perception of this format in comparison with today’s unwritten standard for cinema reproduction – 5.1. Two sample groups were chosen for the experiment - experienced listeners (sound designers and sound design students) and inexperienced listeners; the objective was to examine how these two groups perceive selected formats and whether there is any difference between these two groups. We aimed at five aspects – Spatial Immersion (Envelopment), Localization, Dynamics, Audio Quality, and Format Preference. The results show mostly an insignificant difference between these two groups while both of them slightly leaned towards Dolby Atmos over 5.1.","['Oramus, Tomas', 'Neubauer, Petr']","['Academy of Performing Arts in Prague, Prague, Czech Republic']","Spatial Audio, Part 1",Talk
77,What's Old Is New Again: Using a Physical Scale Model Echo Chamber as a Real-Time Reverberator,"This paper presents a method using physical scale models as echo chambers. The proposed framework creates a partitioned convolution engine where the convolution processing is carried out physically on an up-scaled live audio stream in the model. The resulting reverberated sound is captured and down-scaled, providing the result to the user in real-time. The scale factor can be dynamically changed to explore different room sizes and the reduced dimensions of the scale model make it a tangible reverberation tool. Scale factors up to 1:5 have been tested for full bandwidth, with higher factor possible with improved hardware or in exchange for lowering the upper frequency range, primarily due to driver performance.","['Delcourt, Kevin', 'Zagala, Franck', 'Blum, Alan', 'Katz, Brian F. G.']","['École Nationale Supérieure Louis Lumière, Saint-Denis, France', 'Sorbonne Université, Paris, France']",Room Acoustics,Talk
78,Impulse Response Simulation of a Small Room and in situ Measurements Validation,"The study of reverberation time in room acoustics presents certain drawbacks when dealing with small spaces. In order to reduce the inaccuracies due to the lack of space for placing measurement devices, finite element methods become a good alternative to support measurement results or to predict the reverberation time on the bases of calculating impulse responses. This paper presents a comparison of the reverberation time obtained by means of in situ and simulated impulse responses. The impulse response is simulated using time-domain finite elements methods. The used room for measurements and simulations is a control room of Universidad de Las Americas. Results show a measured mean absolute error of 0.04 s compared to the computed reverberation time.","['Núñez-Solano, Daniel', 'Puyana-Romero, Virginia', 'Ordóñez-Andrade, Cristian', 'Bravo-Moncayo, Luis', 'Garzón-Pico, Christiam']","['University of Las Américas, Quito, Ecuador']",Room Acoustics,Poster
79,Discrimination of High-Resolution Audio without Music,"Nowadays, High-Resolution (Hi-Res) audio format, which has higher sampling frequency (Fs) and quantization bit number than the Compact disc (CD) format, is becoming extremely popular. Several studies have been conducted to clarify whether these two formats can be distinguished. However, most of the studies were conducted by only using music sources to reach a conclusion. In this paper we will try to bring out the problems due to the primary use of music sources for experimental purposes. We will also answer the question related to discrimination between hi-Res and CD formats using sources other than music, such as noise.","['Fukuda, Yuki', 'Ishimitsu, Shunsuke']","['Hiroshima City University, Hiroshima-shi, Japan']",Perception,Poster
80,"The Influences of Microphone System, Video, and Listening Position on the Perceived Quality of Surround Recording for Sport Content","This paper investigates the influences of the recording/reproduction format, video, and listening position on the quality perception of surround ambience recordings for sporting events. Two microphone systems—First Order Ambisonics (FOA) and Equal Segment Microphone Array (ESMA)—were compared in both 4-channel (2D) and 8-channel (3D) loudspeaker reproductions. One subject group tested audio-only conditions while the other group was presented with video as well as audio. Overall, the ESMA was rated significantly higher than the FOA for all quality attributes tested regardless of the presence of video. The 2D and 3D reproductions did not have a significant difference within each microphone system. Video had a significant interaction with the microphone system and listening position depending on the attribute.","['Moulson, Aimee', 'Lee, Hyunkook']","['University of Huddersfield, Huddersfield, UK']",Spatial Audio,Poster
81,Application of Matrix Analysis for Derivation of Acoustical Impedance of Horns,"The direct measurement of a horn’s acoustical impedance requires knowledge of both the sound pressure and volume velocity at the throat of the horn. While measuring sound pressure is trivial, the measurement of volume velocity requires special equipment. This work proposes a new derivation method for the acoustical impedance of a horn. The method is based on matrix analysis and consists of two stages: derivation of the compression driver’s square transfer matrix of A-parameters, and measurement of electrical impedance and sound pressure at the throat of the horn. These functions yield two matrix equations that relate measured sound pressure and electrical impedance, which allows for an acoustical impedance derivation of the horn. A comparison with COMSOL simulation is provided.","['Voishvillo, Alexander', 'Kákonyi, Balázs', 'McLaughlin, Brian']","['Harman Professional Solutions, Northridge, CA, USA']",Transducers,Talk
82,Perceptually Motivated Hearing Loss Simulation for Audio Mixing Reference,"This paper proposes the development of a hearing loss simulation for use in audio mix referencing, designed according to psychoacoustic and audiology research findings. The simulation proposed in this paper aims to reproduce four perceptual aspects of hearing loss; threshold elevation, loss of dynamic range, reduced frequency and temporal resolution, while providing an audio input/output functionality.","['Mourgela, Angeliki', 'Agus, Trevor', 'Reiss, Joshua D.']","['Queen Mary University of London, London, UK', 'Queens University Belfast, Belfast, UK']",Audio Signal Processing,Talk
83,Subjective Assessment of the Versatility of Three-Dimensional Near-Field Microphone Arrays for Vertical and Three-Dimensional Imaging,"This investigation examines the operational size-range of audio images recorded with advanced close-capture microphone arrays for three-dimensional imaging. It employs a 3D panning tool to manipulate audio images. The 3D microphone arrays used in this study were: Coincident-XYZ, M/S-XYZ, and Non-coincident-XYZ/five-point. Instruments of the orchestral string, woodwind, and brass sections were recorded. The objective of the test was to determine the point of three-dimensional expansion onset, preferred imaging, and image breakdown point. Subjects were presented with a continuous dial to manipulate the three-dimensional spread of the arrays, allowing them to expand or contract the microphone signals from 0° to 90° azimuth/elevation. The results showed that the M/S-XYZ array is the perceptually “biggest” of the capture systems under test and displayed the fasted sense of expansion onset. The coincident and non-coincident arrays are much less agreed upon by subjects in terms of preference in particular, and also in expansion onset.","['Martin, Bryan', 'Kelly, Jack', 'Leonard, Brett']","['McGill University, Montreal, QC, Canada', 'Centre for Interdisciplinary Research in Music Media and Technology (CIRMMT), Montreal, QC, Canada', 'University of Indianapolis, Indianapolis, IN, USA', 'The Chelsea Music Festival, New York, NY, USA']","Spatial Audio, Part 1",Talk
84,Modifying Audio Signals for Reproduction with Reduced Room Effect,"Conventionally, equalizers are applied when reproducing audio signals in rooms to reduce coloration and effect of room resonances. Another approach, filtering audio signals with an inverse of the room impulse response (RIR), can theoretically eliminate the effect of the room in one point. But practical issues arise such as impaired sound at other positions, a need to update when RIRs change, and loudspeaker-challenging signals. A technique is presented, which modifies the time-frequency envelopes (spectrogram) of audio signals, such that the corresponding spectrogram in the room is more similar to the original signal’s spectrogram, i.e., room effect is attenuated. The proposed technique has low sensitivity on RIR and listener position changes.","['Faller, Christof']","['Illusonic GmbH, Uster, Zürich, Switzerland']",Audio Signal Processing,Talk
85,Modeling between Partial Components for Musical Timbre Imitation and Migration,"Most musical sounds have strong and regularly distributed spectral components such as harmonic partials. However, the energy distribution patterns between any two such sonic partials, the in-between low-energy signal patterns such as performance articulation or instrument signatures, are also important for characterizing musical sounds. This paper presents a timbre-modeling framework for detecting and modeling the between-partial components for musical timbre analysis and synthesis. This framework focuses on timbre imitation and migration for electronic music instruments, where timbral patterns obtained from acoustical instruments are re-interpreted for electronic instruments and new music interfaces. The proposed framework will help musicians and audio engineers to better explore musical timbre and musical performance expressions for enhancing the naturalness, expressiveness, and creativeness of electronic/computer music systems.","['Kihiko, Angela C.', 'Ogihara, Mitsunori', 'Ren, Gang', 'Beauchamp, James W.']","['Spelman College, Atlanta, GA, USA', 'University of Miami, Coral Gables, FL, USA', 'University of Illinois, Urbana, IL, USA']",Audio Signal Processing,Talk
86,Spatial B-Format Equalization,"Audio corresponding to the moving picture of a virtual reality (VR) camera can be recorded using a VR microphone. The resulting A or B-format channels are decoded with respect to the look-direction for generating binaural or multichannel audio following the visual scene. Existing post-production tools are limited to only linear matrixing and filtering of the recorded channels when only the signal of a VR microphone is available. A time-frequency adaptive method is presented: providing native B-format manipulations, such as equalization, which can be applied to sound arriving from a specific direction with a high spatial resolution, yielding a backwards compatible modified B-format signal. Both linear and adaptive approaches are compared to the ideal case of truly equalized sources.","['Favrot, Alexis', 'Faller, Christof']","['Illusonic GmbH, Uster, Switzerland']","Spatial Audio, Part 3",Talk
87,A Novel Spatial Impulse Response Capture Technique for Realistic Artificial Reverberation in the 22.2 Multichannel Audio Format,"As immersive media content and technology begin to enter the marketplace, the need for truly immersive spatial reverberation tools takes on a renewed significance. A novel spatial impulse response capture technique optimized for the 22.2 multichannel audio format is presented. The proposed technique seeks to offer a path for engineers who are interested in creating three-dimensional spatial reverberation through convolution. Its design is informed by three-dimensional microphone techniques for the channel-based capture of acoustic music. A technical description of the measurement system used is given. The processes by which the spatial impulse responses are captured and rendered, including deconvolution and loudness normalization, are described. Three venues that have been measured using the proposed technique are presented. Preliminary listening sessions suggest that the array is capable of delivering a convincing three-dimensional reproduction of several acoustic spaces with a high degree of fidelity. Future research into the perception of realism in spatial reverberation for immersive music production is discussed.","['Kelly, Jack', 'King, Richard', 'Woszczyk, Wieslaw']","['McGill University, Montreal, QC, Canada', 'The Centre for Interdisciplinary Research in Music Media and Technology, Montreal, Quebec, Canada']",Room Acoustics,Poster
88,Comparison of Human and Machine Recognition of Electric Guitar Types,"The classification of musical instruments for instruments of the same type is a challenging task not only to experienced musicians but also in music information retrieval. The goal of this paper is to understand how guitar players with different experience levels perform in distinguishing audio recordings of single guitar notes from two iconic guitar models and to use this knowledge as a baseline to evaluate the performance of machine learning algorithms performing a similar task. For this purpose we conducted a blind listening test with 236 participants in which they listened to 4 single notes from 4 different guitars and had to classify them as a Fender Stratocaster or an Epiphone Les Paul. We found out that only 44% of the participants could correctly classify all 4 guitar notes. We also performed machine learning experiments using k-Nearest Neighbours (kNN) and Support Vector Machines (SVM) algorithms applied to a classification problem with 1292 notes from different Stratocaster and Les Paul guitars. The SVM algorithm had an accuracy of 93.9%, correctly predicting 139 audio samples from the 148 present in the testing set.","['Profeta, Renato', 'Schuller, Gerald']","['Ilmenau University of Technology, Ilmenau, Germany']",Perception,Poster
89,Low Deviation and High Sensitivity—Optimized Exciter Positioning for Flat Panel Loudspeakers by Considering Averaged Sound Pressure Equalization,"Loudspeaker panels represent a class of loudspeakers, whose electrical, mechanical, and acoustical properties differ completely from conventional loudspeakers. However, the acoustic properties are mostly associated with lower performance. The position of the excitation is one of the crucial parameters to optimize multiple parameters such as the frequency response in terms of linearity and sensitivity. This paper describes an approach to find the best excitation position for an exemplary distributed mode loudspeaker (DML) by considering efficiency and the averaged sound pressure equalization. An evaluation of the measured response in the horizontal plane of 25 excitation positions is presented and an optimization algorithm is used to filter every position to a certain acoustical quality standard.","['Zenker, Benjamin', 'Rawoof, Shanavaz Sanjay Abdul', 'Merchel, Sebastian', 'Altinsoy, M. Ercan']","['Technical University Dresden, Dresden, Germany']",Transducers,Talk
90,Objective Measurement of Stereophonic Audio Quality in the Directional Loudness Domain,"Automated audio quality prediction is still considered a challenge for stereo or multichannel signals carrying spatial information. A system that accurately and reliably predicts quality scores obtained by time-consuming listening tests can be of great advantage in saving resources, for instance, in the evaluation of parametric spatial audio codecs. Most of the solutions so far work with individual comparisons of distortions of interchannel cues across time and frequency, known to correlate to distortions in the evoked spatial image of the subject listener. We propose a scene analysis method that considers signal loudness distributed across estimations of perceived source directions on the horizontal plane. The calculation of distortion features in the directional loudness domain (as opposed to the time-frequency domain) seems to provide equal or better correlation with subjectively perceived quality degradation than previous methods, as con?rmed by experiments with an extensive database of parametric audio codec listening tests. We investigate the effect of a number of design alternatives (based on psychoacoustic principles) on the overall prediction performance of the associated quality measurement system.","['Delgado, Pablo', 'Herre, Jürgen']","['International Audio Laboratories Erlangen, Erlangen, Germany', 'Fraunhofer Institute for Integrated Circuits IIS, Erlangen, Germany']",Audio Signal Processing,Poster
91,Describing the Audible Effects of Nonlinear Loudspeaker Distortion,"In order to evaluate how and when listeners hear distortion in a nonlinear loudspeaker model, a three-part study was designed. A variety of audio files were processed through both a linear and a nonlinear loudspeaker model and the input signals were calibrated to produce a prescribed level of distortion in the nonlinear model. Listeners completed subjective experiments in which they heard both versions of the clips, selected the audible attributes they believed changed, and described the differences in their own words. In later tests, listeners marked in time they heard changes in the most commonly used descriptors. A full analysis of listener comments and time-based relationships is explored with theoretical explanations of the results obtained.","['McMullin, Elisabeth', 'Brunet, Pascal', 'Wang, Zhongran']","['Samsung Research America, Valencia, CA USA']",Perception,Talk
92,Realistic Procedural Sound Synthesis of Bird Song Using Particle Swarm Optimization,"We present a synthesis algorithm for approximating bird song using particle swarm optimization to match real bird recordings. Frequency and amplitude envelope curves are first extracted from a bird recording. Further analysis identifies the presence of even and odd harmonics. A particle swarm algorithm is then used to find cubic Bezier curves which emulate the envelopes. These curves are applied to modulate a sine oscillator and its harmonics. The synthesized syllable can then be repeated to generate the sound. Thirty-six bird sounds have been emulated this way, and a real-time web-based demonstrator is available, with user control of all parameters. Objective evaluation showed that the synthesized bird sounds captured most audio features of the recordings.","['Zúñiga, Jorge', 'Reiss, Joshua D.']","['Queen Mary University of London, London, UK']",Audio Signal Processing,Talk
93,"Subjective Graphical Representation of Microphone Arrays for Vertical Imaging and Three-Dimensional Capture of Acoustic Instruments, Part II","This investigation employs a simple graphical method in an effort to represent the perceived spatial attributes of three microphone arrays designed to create vertical and three-dimensional audio images. Three separate arrays were investigated in this study: Coincident, M/S-XYZ, and Non-coincident/Five-point capture. Instruments of the orchestral string, woodwind, and brass sections were recorded. Test subjects were asked to represent the spatial attributes of the perceived audio image on a horizontal/vertical grid and a graduated depth grid, via a pencil drawing. Results show that the arrays exhibit a greater extent in every dimension—vertical, horizontal, and depth—compared to the monophonic image. The statistical trends show that the spatial characteristics of each array are consistent across each dimension. In the context of immersive/3D mixing and post production, a case can be made that the arrays will contribute to a more efficient and improved workflow due to the fact that they are easily optimized during mixing or post-production.","['Martin, Bryan', 'Martin, Denis', 'King, Richard', 'Woszczyk, Wieslaw']","['McGill University, Montreal, QC, Canada', 'Centre for Interdisciplinary Research in Music Media and Technology (CIRMMT), Montreal, QC, Canada']","Recording, Production, and Live Sound",Talk
94,Analysis of a Vented-Box Loudspeaker System via the Impedance Function,"The vented-box loudspeaker system is studied through a small-signal equivalent circuit model via the impedance function. Some traditional models are found to inadequately represent the system losses, lumping them together in an effort to simplify the design process. Here, a low-frequency small-signal equivalent circuit model is proposed, incorporating five loss elements. The impedance function is derived, and system parameters are determined by curve-fitting the impedance function to measured impedance data. It is shown that the reactive elements determine the critical frequencies, and the lossy elements determine the Q-factors or contribute to the impedance level. Moreover, the lossy elements affect the curve-fit in a unique way, allowing their values to be quantified.","['Lazar, James', 'Kubota, Glenn S.']","['Samsung Research America, Valencia, CA, USA']",Transducers,Talk
95,Spatial Auditory Masking for Three-Dimensional Audio Coding,"Spatial auditory masking effects have been examined for developing highly efficient audio coding algorithms for signals in three-dimensional (3D) sound fields. Generally, the masking threshold level is lowered according to the increase of the directional difference between masker and maskee signals. However, we found that when a maskee signal is located at the symmetrical position of the masker signal with respect to the frontal plane of a listener, the masking threshold level is not lowered, which counters the expectations. A mathematical model is proposed to estimate the masking threshold caused by multiple masker signals in the 3D sound field. Using the model, the perceptual entropy of a tune from a two channel stereo CD was reduced by approximately 5.5%.","['Nishiguchi, Masayuki', 'Kato, Kodai', 'Watanabe, Kanji', 'Abe, Koji', 'Takane, Shouichi']","['Akita Prefectural University, Yurihonjo Akita, Japan']",Perception,Talk
96,Comparing Externalization Between the Neumann KU100 Versus Low Cost DIY Binaural Dummy Head,"Music is usually recorded using traditional microphone techniques. With technology continually advancing, binaural recording has become more popular, that is, a recording where two microphones are used to create a three-dimensional stereo image. Commercially available binaural heads are prohibitively expensive and not practical for use in typical educational environments or for casual use in a home studio. This experiment consisted of gathering recorded stimuli with a homemade binaural head and the Neumann KU 100. The recordings were played back for 34 subjects instructed to rate the level of externalization for each example. The study investigates whether a homemade binaural head made for under $500 can externalize sound as well as a commercially available binaural head the Neumann KU 100.","['DiPasquale, Kelley Jayne']","['SUNY Potsdam, Crane School of Music, Potsdam, NY, USA']",Spatial Audio,Poster
97,Optimum Measurement Locations for Large-Scale Loudspeaker System Tuning Based on First-Order Reflections Analysis,"This paper investigates how first-order reflections impact the response of sound reinforcement systems over large audiences. On the field, only few acoustical measurements can be performed to drive tuning decisions. The challenge is then to select the right measurement locations so that it provides an accurate representation of the loudspeaker system response. Simulations of each first-order reflection (e.g., floor or side wall reflection) are performed to characterize the average frequency response and its variability over the target audience area. Then, the representativity of measurements performed at a reduced number of locations is investigated. Results indicate that a subset of eight measurement locations spread over the target audience area represents a rational solution to characterize the loudspeaker system response.","['Moulin, Samuel', 'Corteel, Etienne', 'Montignies, François']","['L-Acoustics, Marcoussis, France']",Room Acoustics,Talk
98,Investigating Room-Induced Influences on Immersive Experience Part II: Effects Associated with Listener Groups and Musical Excerpts,"The authors previously compared four distinct multichannel playback rooms and showed that perceived spatial attributes of program material (width, depth, and envelopment) were similar across all four rooms when reproduced through a 22-channel loudspeaker array. The present study further investigated perceived auditory immersion from two additional variables: listener group and musical style. We found a three-way interaction of variables, MUSIC x (playback) ROOM x GROUP for 22-channel reproduced music. The interaction between musical material and playback room acoustics differentiates perceived auditory immersion across listener groups. However, in the 2-channel reproductions, the room and music interaction is prominent enough to flatten inter-group differences. The 22-channel reproduced sound fields may have shaped idiosyncratic cognitive bases for each listener group.","['Kim, Sungyoung', 'Sakamoto, Shuichi']","['Rochester Institute of Technology, Rochester, NY, USA', 'Tohoku University, Sendai, Japan']","Spatial Audio, Part 1",Talk
99,Immersive Sound Reproduction in Real Environments Using a Linear Loudspeaker Array,In this paper an immersive sound reproduction system capable of improving the overall listening experience is presented and tested using a loudspeaker linear array. The system aims at providing a channel separation over a broadband spectrum by implementing the RACE (Recursive Ambiophonic Crosstalk Elimination) algorithm and a beamforming algorithm based on a pressure matching approach. A real time implementation of the algorithm has been performed and its performance has been evaluated comparing it with the state of the art. Objective and subjective measurements have con?rmed the effectiveness of the proposed approach.,"['Bruschi, Valeria', 'Ortolani, Nicola', 'Cecchi, Stefania', 'Piazza, Francesco']","['Univeresità Politecnica delle Marche, Ancona, Italy']",Spatial Audio,Poster
100,Microphone Comparison: Spectral Feature Mapping for Snare Drum Recording,"Microphones are known to exhibit sonic differences and microphone selection is integral in achieving desired tonal qualities of recordings. In this paper an initial multi-stimuli listening test is used to categorize microphones based on user preference when recording snare drums. A spectral modification technique is then applied to recordings made with a microphone from the least preferred category, such that they take on the frequency characteristics of recordings from the most preferred category. To assess the success of the audio transformation, a second experiment is undertaken with expert listeners to gauge pre- and post-transformation preferences. Results indicate spectral transformation dramatically improves listener preference for recordings from the least preferred category, placing them on par with those of the most preferred.","['Cheshire, Matthew', 'Stables, Ryan', 'Hockman, Jason']","['Birmingham City University, Birmingham, UK']","Recording, Production, and Live Sound",Talk
101,A Latency Measurement Method for Networked Music Performances,"The New York University and the Leibniz University Hannover are working on future immersive Networked Music Performances. One of the biggest challenges of audio data transmission over IP-based networks is latency, which can affect the interplay of the participants. In this contribution, two metronomes, utilizing the Global Positioning System to generate a globally synchronized click signal, were used as a tool to determine delay times in the data transmission between both universities with high precision. The aim of this ?rst study is to validate the proposed method by obtaining insights into transmission latency as well as latency ?uctuations and asymmetries. This work also serves as baseline for future studies and helps to establish an effective connection between the two institutions.","['Hupke, Robert', 'Sridhar, Sripathi', 'Genovese, Andrea', 'Nophut, Marcel', 'Preihs, Stephan', 'Beyer, Tom', 'Roginska, Agnieszka', 'Peissig, Jürgen']","['Leibniz Universität Hannover, Hannover, Germany', 'New York University, New York, NY, USA']",Applications in Audio,Poster
102,Summed Efficiency-Method for Efficient Vented Box Speaker Design,"Loudspeakers are inefficient and conventional design methods do not consider the efficiency in the design process. With the rise of Digital Signal Processing (DSP) the frequency response can be corrected with pre-filtering. Based on a frequency domain analysis of vented box enclosures this paper proposes a new method, the Summed efficiency-method (S?-method), for designing vented box enclosures. The method focuses on mapping the efficiency and SPL output vs. volume and tuning frequency enabling the designer to perform knowledge-based trade-off decisions in the design process. A design example shows how the method can be used to improve the efficiency with over 70% compared to a conventional maximum flat alignment for a compact Public Address (PA) subwoofer application.","['Iversen, Niels Elkjær', 'Christensen, Theis', 'Bjørnskov, Anders', 'Petersen, Lars']","['ICEpower a/s, Copenhagen, Denmark', 'Technical University of Denmark, Kgs. Lyngby, Denmark']",Product Development,Talk
103,Detection of the Effect of Window Duration in an audio Source Separation Paradigm,Non-negative matrix factorization (NMF) is a commonly used method for audio source separation in applications such as polyphonic music separation and noise removal. Previous research evaluated the use of additional algorithmic components and systems in efforts to improve the effectiveness of NMF. This study examined how the short-time Fourier transform (STFT) window duration used in the algorithm might affect detectable differences in separation performance. An ABX listening test compared speech extracted from two types of noise-contaminated mixtures at different window durations to determine if listeners could discriminate between them. It was found that the window duration had a significant impact on subject performance in both white- and conversation-noise cases with lower scores for the latter condition.,"['Miller, Ryan', 'Bulla, Wesley', 'Tarr, Eric']","['Belmont University, Nashville, TN, USA']",Audio Signal Processing,Poster
104,Calibration Approaches for Higher Order Ambisonic Microphones,"Recent years have seen an increase in the capture and production of ambisonic material due to companies such as YouTube and Facebook utilizing ambisonics for spatial audio playback. Consequently, there is now a greater need for affordable high order microphone arrays due to this uptake in technology. This work details the development of a five-channel circular horizontal ambisonic microphone intended as a tool to explore various optimization techniques, focusing on capsule calibration & pre-processing approaches for unmatched capsules.","['Middlicott, Charles', 'Wiggins, Bruce']","['University of Derby, Derby, UK']",Spatial Audio,Poster
105,Analyzing and Extracting Multichannel Sound Field,"Current post production workflow requires sound engineers to create multiple multichannel audio delivery formats. Inaccurate translation between formats may lead to more time and cost for extra manual adjustment; whereas in sound reproduction, it causes misinterpretation of the original mix and deviation from the intended story. This paper proposes a method that combines both analyzing an encoded Ambisonics field from the input multichannel signal and analyzing between each pair of adjacent channels. This allows an overall understanding of the multichannel sound field while having the ability to have a fine extraction from each channel pair. The result can be used to translate between multichannel formats and also to provide a more accurate rendering for immersive stereo playback.","['Hsieh, Pei-Lun']","['Ambidio, Glendale, CA, USA']",Audio Signal Processing,Talk
106,Distortion Modeling of Nonlinear Systems Using Ramped-Sines and Lookup Tables,"Nonlinear systems identification is used to synthesize black-box models of nonlinear audio effects and as such is a widespread topic of interest within the audio industry. As a variety of implementation algorithms provide a myriad of approaches, questions arise whether there are major functional differences between methods and implementations. This paper presents a novel method for the black-box measurement of distortion characteristic curves and an analysis of the popular “lookup table” implementation of nonlinear effects. Pros and cons of the techniques are examined from a signal processing perspective and the basic limitations and efficiencies of the approaches are discussed.","['Mayo, Paul', 'Bulla, Wesley']","['University of Maryland, College Park, MD, USA', 'Belmont University, Nashville, TN, USA']",Audio Signal Processing,Poster
107,Effects of Capsule Coincidence in FOA Using MEMS: Objective Experiment,"This paper describes an experiment attempting to determine the effects of capsule coincidence in First Order Ambisonic (FOA) capture. While the spatial audio technique of ambisonics has been widely researched, it continues to grow in interest with the proliferation of AR and VR devices and services. Specifically, this paper attempts to determine whether the increased capsule coincidence afforded by Micro-Electronic Mechanical Systems (MEMS) capsules can help increase the impression of realism in spatial audio recordings via objective and subjective analysis. This is the first of a two-part paper.","['Zalles, Gabriel']","['University of California, San Diego, La Jolla, CA, USA']","Spatial Audio, Part 3",Talk
108,Precise Temporal Localization of Sudden Onsets in Audio Signals Using the Wavelet Approach,"Presently reported is a wavelet-based method for the temporal localization of sudden onsets in audio signals with sub-millisecond precision. The method only requires O(n) operations, which is highly efficient. The entire audio signal can be processed as a whole without the need to be broken down into individual windowed overlapping blocks. It can also be processed in a streaming mode compatible with real-time processing. In comparison with time-domain and frequency-domain methods, the wavelet-based method proposed here offers several distinct advantages in sudden onset detection, temporal localization accuracy, and computational cost, which may therefore find broad applications in audio signal processing and music information retrieval.","['Wan, Yuxuan', 'Chen, Yijia', 'Sim, Keegan Yi Hang', 'Wu, Lijia', 'Geng, Xianzheng', 'Chau, Kevin']","['Hong Kong University of Science and Technology, Clean Water Bay, Hong Kong']",Semantic Audio,Talk
109,Synthesis of Binaural Room Impulse Responses for Different Listening Positions Considering the Source Directivity,"A popular goal in research on virtual and augmented acoustic realities is the implementation of realistic room acoustics and sound source characteristics. Additionally, listeners want to move around, explore the virtual or augmented environments. One way to realize position-dynamic synthesis is the use of binaural technologies on the basis of real measurements. While this approach allows to successfully reproduce the real acoustic environment, many positions need to be measured. To reduce the time effort new methods are invented to calculate binaural room impulse responses from few positions. The presented work enhances existing synthesis methods by including predefined sound source directivities into calculation of binaural room impulse responses. The results are analyzed in a physical and in a perceptive way.","['Sloma, Ulrike', 'Klein, Florian', 'Werner, Stephan', 'Pappachan Kannookadan, Tyson']","['Technische Universität Ilmenau, Ilmenau, Germany']",Room Acoustics,Talk
110,The Generation Gap—Perception and Workflow of Analog vs. Digital Mixing,"Are sound engineers showing preference for the mixing technology of their generation? We interviewed producer Ezequiel Morfi who owns TITANIO in Buenos Aires and contrasted his opinions with those of four mixers based in Western Canada who were required to use analog-only or digital-only mixing tools when preparing stimuli for this study. To ascertain the myths about which technology sounds superior, 19 trained listeners of ages 17–37 compared analog and digital mixing versions of 8 pop-rock tracks in a double-blind listening test. The main results showed that the analog version of one track was significantly preferred by 79% of the listeners (p=.02), and we observed a slight trend towards the significance of age on preference for the analog format (p=.09).","['Chambers-Moranz, Ryland', 'Pras, Amandine', 'Thomas, Nate']","['University of Lethbridge, Lethbridge, AB, Canada', 'School for Advanced Studies in the Social Sciences, Paris, France']",Audio Education,Talk
111,Digital Parametric Filters Beyond Nyquist Frequency,"Filter Digitization through the Bilinear Transformation is often considered a very good all-around method to produce equalizer sections. The method is well behaved in terms of stability and ease of implementation; however, the frequency warping produced by the transformation leads to abnormalities near the Nyquist frequency. Moreover, it is impossible to design parametric sections whose analog center frequencies are defined above the Nyquist frequency. These filters, even with center frequencies outside of the hearing range, have effects that extend into the hearing bandwidth with desirable characteristics during mixing and mastering. Surpassing these limitations, while controlling the abnormalities of the warping produced by the Bilinear Transform through an alternative definition of the Bilinear constant is the purpose of this paper. In the process, also a correction factor is discussed for the bandwidth of the parametric section to correct abnormalities affecting the digitization of this parameter.","['Sierra, Juan']","['Stanford University, Stanford, CA, USA']",Audio Signal Processing,Talk
112,Simplified Source Directivity Rendering in Acoustic Virtual Reality Using the Directivity Sample Combination,"This contribution proposes a simplified rendering of source directivity patterns for the simulation and auralization of auditory scenes consisting of multiple listeners or sources. It is based on applying directivity filters of arbitrary directivity patterns at multiple, supposedly important directions, and approximating the filter outputs of intermediate directions by interpolation. This reduces the amount of required filtering operations considerably and thus increases the computational efficiency of the auralization. As a proof of concept, the simplification is evaluated from a technical as well as from a perceptual point of view for one specific use case. The promising results suggest further studies of the proposed simplification in the future to assess its applicability to more complex scenarios.","['Götz, Georg', 'Pulkki, Ville']","['Aalto University, Espoo, Finland']","Spatial Audio, Part 2",Talk
113,Evaluation of Multichannel Audio in Automobiles versus Mobile Phones,"Multichannel surround and 3D audio are slowly gaining popularity and eventually commercial content in these formats will become common. Many automobiles still have a stereo sound system with some firmware or software that is capable of rendering multichannel audio into stereo. This paper shows the results of a listening test for multichannel audio conducted in a medium-sized car. The results of this test are compared to the results of a listening test for the same audio excerpts but conducted on a mobile phone with headphones. The results show that on mobile phones, multichannel audio clearly outperforms stereo in terms of perceived audio quality as rated by a user. However in automobiles, multichannel audio only shows marginal improvement in the rated audio quality.","['Toosy, Fesal', 'Ehsan, Muhammad Sarwar']","['University of Central Punjab, Lahore, Pakistan']",Applications in Audio,Talk
114,Investigating the Importance of Height Channels of Cinema Surround Systems,"Considering multichannel audio content; a room’s acoustics might conflict or maybe assist the target space in some cases. There are inherent limitations of some of the existing surround layouts; such as elevation and directivity, which are crucial elements in sound reproduction in a multichannel format. In this paper we investigate the importance of surround-height channels and its effect on the listening experience in a surround environment. A listening experiment was conducted in which ten untrained listeners were asked to compare seven reproduced sound effects on three different surround systems. Results have indicated that surround-height loudspeakers have a greater influence on perceived sound quality and localization of sound sources.","['Shalabi, Ahmed']","['Overdub Productions, London, UK']",Spatial Audio,Poster
115,Perceptually Affecting Electrical Properties of Headphone Cable — Factor Hunting Approach,"An approach to find the cause of the perceptual sound quality change by headphone cable has been proposed. This is a method of verifying the validity of the selected candidate by selecting candidate factors from the measurement results, simulating them by digital signal processing, and evaluating the simulated sounds by audition. In the headphone cable, it was found that the factor is that the inductance changes due to the flowing current. It has become clear from the experimental results that changes in transfer characteristics are very sensitively affecting the perceptual sound quality.","['Yoneya, Akihiko']","['Nagoya Institute of Technology, Nagoya, Aichi-pref., Japan']",Applications in Audio,Poster
116,SALTE Pt. 1: A Virtual Reality Tool for Streamlined and Standardized Spatial Audio Listening Tests,"This paper presents SALTE (Spatial Audio Listening Test Environment), an open-source framework for creating spatial audio perceptual testing within virtual reality (VR). The framework incorporates standard test paradigms such as MUSHRA, 3GPP TS 26.259 and audio localization. The simplified drag-and-drop user interface facilitates rapid and robust construction of customized VR experimental environments within Unity3D without any prior knowledge of the game engine or the C# coding language. All audio is rendered by the dedicated SALTE audio renderer which is controlled by dynamic participant data sent via Open Sound Control (OSC). Finally, the software is capable of exporting all experimental conditions such as visuals, participant interaction mechanisms, and test parameters allowing for streamlined and standardized comparable data within and in-between organizations.","['Johnston, Daniel', 'Tsui, Benjamin', 'Kearney, Gavin']","['University of York, York, UK']",Spatial Audio,Poster
117,Modelling and Measurement of Nonlinear Intermodal Coupling in Loudspeaker Diaphragm Vibrations,"Accurate prediction of the nonlinear transfer response of loudspeakers in the full band is relevant to optimize the development of audio products. Small size, light, and efficient transducers require low density and thin diaphragms, which may vibrate nonlinearly even at low amplitudes impairing the sound quality. This paper proposes an extension of the existing transducer model comprising breakup modes with geometrical nonlinearities, adding the nonlinear coupling effect between the piston mode and the breakup modes responsible for large intermodulation problems. A novel measurement technique to estimate the breakup frequency modulation induced by the piston mode excursion is presented, the model is validated with measurements of harmonic and intermodulation distortion and other symptoms relevant for assessment of acoustic performance.","['Cardenas, William']","['ORA Graphine Audio Inc., Montreal, Quebec, Canada']",Transducers,Talk
118,Perceptual Assessment of Distortion in Low-Frequency Loudspeakers,"A perceptually-driven distortion metric for loudspeakers is proposed that is based on a critical-band spectral comparison of the distortion and noise to an appropriate masking threshold. The loudspeaker is excited by a sine-wave signal composed of windowed 0.3 second bursts. Loudspeaker masking curves for sine waves between 20–500 Hz are derived from previously published ones for headphone distortion evaluation and expanded to curves at 1 decibel increments by linear interpolation and extrapolation. For each burst, the ratios of measured distortion and noise levels to the appropriate masking curve values are determined for each critical band starting at the second harmonic. Once this is done the audibility of all these contributions are combined into various audibility values.","['Fielder, Louis', 'Smithers, Michael']","['Retired, Millbrae, CA, USA', 'Dolby Laboratories, Sydney, NSW, Australia']",Transducers,Talk
119,Multi-Scale Auralization for Multimedia Analytical Feature Interaction,"Modern human-computer interaction systems use multiple perceptual dimensions to enhance intuition and efficiency of the user by improving their situational awareness. A signal processing and interaction framework is proposed for auralizing signal patterns and augmenting the visualization-focused analysis tasks of social media content analysis and annotations, with the goal of assisting the user in analyzing, retrieving, and organizing relevant information for marketing research. Audio signals are generated from video/audio signal patterns as an auralization framework, for example, using the audio frequency modulation that follows the magnitude contours of video color saturation. The integration of visual and aural presentations will benefit the user interactions by reducing the fatigue level and sharping the users’ sensitivity, thereby improving work efficiency, confidence, and satisfaction.","['Nguyen, Nguyen Le Thanh', 'Lee, Hyunhwan', 'Johnson, Joseph', 'Ogihara, Mitsunori', 'Ren, Gang', 'Beauchamp, James W.']","['University of Miami, Coral Gables, FL, USA', 'University of Illinois at Urbana-Champaign, Urbana, IL, USA']",Audio Signal Processing,Talk
120,Compensation Filters for Excess Exciter Excursion on Flat-Panel Loudspeakers,"Inertial exciters are used to actuate a surface into bending vibration, producing sound, but often have a high-Q resonance that can cause the exciter magnet to displace enough to contact the bending panel. The magnet contacting the panel can cause distortion and possibly even damage to the exciter or panel while having a minimal contribution to acoustic output. A method is outlined for deriving a digital biquad filter to cancel out the excessive displacement of the magnet based on measurements of the exciter’s resonant frequency and Q-factor. Measurements of exciter and panel displacement demonstrate that an applied filter reduces magnet excursion by 20 dB at the resonant frequency.","['Anderson, David A.']","['University of Pittsburgh, Pittsburgh, PA, USA']",Applications in Audio,Poster
121,Is Binaural Spatialization the Future of Hip-Hop?,"Modern hip-hop is typically associated with samples and MIDI and not so much with creative source spatialization since the energy-driving elements are usually located in the center of a stereo image. To evaluate the impact of certain element placements behind, above, or underneath the listener on the listening experience, we experimented beyond standard mixing practices by spatializing beats and vocals of two hip-hop tracks in different ways. Then, 16 hip-hop musicians, producers, and enthusiasts, and three audio engineers compared a stereo and a binaural version of these two tracks in a perceptual experiment. Results showed that hip-hop listeners expect a few elements, including the vocals, to be mixed conventionally in order to create a cohesive mix and to minimize distractions.","['Turner, Kierian', 'Pras, Amandine']","['University of Lethbridge, Lethbridge, AB, Canada', 'School for Advanced Studies in the Social Sciences, Paris, France']",Applications in Audio,Poster
122,Spherical Microphone Array Shape to Improve Beamforming Performance,"A 360-degree steerable super-directional beamforming are proposed. We designed a new acoustic baffle for spherical microphone array to achieve both small size and high performance. The shape of baffle is a sphere with parabola-like depressions; therefore, sound-collection performance can be enhanced using reflection and diffraction. We first evaluated its beamforming performance through simulation then fabricated a 3D prototype of an acoustic baffle microphone array with the proposed baffle shape and compared its performance to that of a conventional spherical 3D acoustic baffle. This prototype exhibited better beamforming performance. We built microphone array system that includes the proposed acoustic baffle and a 360-degree camera, our system can pick up match sound to an image in a specific direction in real-time or after recording. We have received high marks from users who experienced the system demo.","['Yazawa, Sakurako', 'Itou, Hiroaki', 'Noguchi, Ken’ichi', 'Kobayashi, Kazunori', 'Harada, Noboru']","['NTT Corporation, Tokyo, Japan']",Transducers,Poster
123,Noise and Distortion Mechanisms Encountered in Switching Audio Power Amplifier Design,"When designing a switching power amplifier, many phenomena are encountered that leave the designer wondering why performance falls short of what theory predicts. While many sources of non-linearity and noise in the conversion process are known and intrinsic to the sub-systems involved, other sources of error are more subtle. The intent of this paper is to outline the noise, distortion, and error mechanisms commonly encountered in practice when designing a switching (Class-D) power amplifier. By understanding the root cause of these mechanisms, a more heuristic approach can be employed in switching power amplifier design. The focus will be on analog systems employing clocked, naturally sampled modulators, but the bulk of the material will be broadly applicable to any modulation scheme.","['Muniz, Robert']","['Harmonic Power Conversion LLC, Douglas, MA, USA']",Transducers,Talk
124,Towards a Pedagogy of Multitrack Audio Resources for Sound Recording Education,"This paper describes preliminary research into pedagogical approaches to teach and train sound recording students using multitrack audio recordings. Two recording sessions are described and used to illustrate where there is evidence of technical, musical, and socio-cultural knowledge in multitrack audio holdings. Approaches for identifying, analyzing, and integrating this into audio education are outlined. This work responds to the recent AESTD 1002.2.15-02 recommendation for delivery of recorded music projects and calls from within the field to address the advantages, challenges, and opportunities of including multitrack recordings in higher education teaching and research programs.","['McNally, Kirk', 'Thompson, Paul', 'Scott, Ken']","['University of Victoria, School of Music, Victoria, BC, Canada', 'Leeds Beckett University, Leeds, West Yorkshire, UK']",Audio Education,Talk
125,Noise Robustness Automatic Speech Recognition with Convolutional Neural Network and Time Delay Neural Network,"To improve the performance of automatic speech recognition in noisy environments, the convolutional neural network (CNN) combined with time-delay neural network (TDNN) is introduced, which is referred as CNN-TDNN. The CNN-TDNN model is further optimized by factoring the parameter matrix in the time-delay neural network hidden layers and adding a time-restricted self-attention layer after the CNN-TDNN hidden layers. Experimental results show that the optimized CNN-TDNN model has better performance than DNN, CNN, TDNN, and CNN-TDNN. The average recognition word error rate (WER) can be reduced by 11.76% when comparing with the baselines.","['Wang, Jie', 'Wang, Dunze', 'Chen, Yunda', 'Lu, Xun', 'Zheng, Chengshi']","['Guangzhou University, Guangzhou, China', 'Power Grid Planning Center, Guandgong Power Grid Company, Guangdong, China', 'Institute of Acoustics, Chinese Academy of Sciences, Beijing, China']",Applications in Audio,Poster
126,Improvement of DNN-Based Speech Enhancement with Non-Normalized Features by Using an Automatic Gain Control,"Speech enhancement performance may degrade when the peak level of the noisy speech is significantly different from the training datasets in Deep Neural Networks (DNN)-based speech enhancement algorithms, especially when the non-normalized features are used in practical applications, such as log-power spectra. To overcome this shortcoming, we introduce an automatic gain control (AGC) method as a preprocessing technique. By doing so, we can train the model with the same peak level of all the speech utterances. To further improve the proposed DNN-based algorithm, the feature compensation method is combined with the AGC method. Experimental results indicate that the proposed algorithm can maintain consistent performance when the peak of the noisy speech changes in a large range.","['Cheng, Linjuan', 'Zheng, Chengshi', 'Peng, Renhua', 'Li, Xiaodong']","['Institute of Acoustics, Chinese Academy of Sciences, Beijing, China', 'Chinese Academy of Sciences, Beijing, China']",Audio Signal Processing,Poster
127,Mitigating the Effect of In-Vehicle Road Noise Cancellation on Music Playback,"A Road Noise Cancellation (RNC) system is an Active Noise Cancellation (ANC) system implemented in a vehicle in order to minimize undesirable road noise inside the passenger cabin. Current RNC systems undesirably affect the frequency response of music playback. The RNC system’s error microphones sense all the sound in the passenger cabin, including the music. Hence, RNC systems will cancel this total sensed sound and not only the road induced noise. A new True Audio algorithm can directly remove the music signal from the error microphone signals and leave only the interior noise portion. In order to correctly estimate the music portion at the error microphones, True Audio implements a novel control topology based on a new multiple channel, real time modeling of the music’s secondary path transfer function. To validate the effectiveness of the proposed algorithm, experimental and numerical simulations were performed. The numerical studies use logs of real sensors mounted on a vehicle forming an RNC system with six reference accelerometers, five control speakers and six error microphones. Both the models and measurements show that the True Audio algorithm preserves the frequency response of music when the RNC system is activated.","['Feng, Tao', 'Bastyr, Kevin']","['Harman International, Novi, MI, USA']",Applications in Audio,Talk
128,A Method for Three-Dimensional Horn Geometry Optimization,"A method for three dimensional (3D) horn geometry optimization is introduced. The method uses 3D Computer Aided Design (CAD) combined with Finite Element Analysis (FEA), the Boundary Element Method (BEM) and scientific programming where: the acoustical properties of horn geometry parametrized in CAD are analyzed using FEA and BEM, and scientific programming is used to manipulate the parametrized geometry and optimize the horn according to specified objective functions. The example of a horn design using this method is presented together with measurements of the resulting geometry.","['Smolen, Christopher', 'Halley, Jerome']","['QSC, LLC, Costa Mesa, CA, USA']",Product Development,Talk
129,Applying Sound Equalization to Vibrating Sound Transducers Mounted on Rigid Panels,"In recent years, loudspeaker manufacturers have proposed to the market vibrating sound transducers (also called shakers or exciters) that can be installed on a surface or a panel to be transformed in invisible speakers capable of delivering sound. These systems show different frequency behaviors mainly depending on the type and size of the surface. Therefore, an audio equalization is crucial to enhance the sound reproduction performance achieving flat frequency responses. In this paper a multi-point equalization procedure is applied to several surfaces equipped with vibrating transducers, showing its positive effect from objective and subjective point of view.","['Cecchi, Stefania', 'Terenzi, Alessandro', 'Piazza, Francesco', 'Bettarelli, Ferruccio']","['Universitá Politecnica della Marche, Ancona, Italy', 'Universita Politecnica delle Marche, Ancona, Italy', 'Universitá Politecnica della Marche, Ancona (AN), Italy', 'Leaff Engineering, Osimo, Italy']",Transducers,Poster
130,"Production Processes of Pop Music Arrangers in Bamako, Mali","Bamako, economic capital of Mali in West Africa, saw the recent multiplication of digital studios based on Cubase 5, FL Studio, cracked plugins, a MIDI keyboard, and a small cabin with a cheap condenser microphone and a pop-filter. From videos and screen captures of recording sessions in three of these studios, we analyzed the creative process of four DAW practitioners from the beginning of the beat production to the mastering of the track. We also examined their interaction with the singers and rappers. Our analyses showed that young Malian DAW practitioners constantly revisit their MIDI arrangement and vocal recordings with advanced editing techniques. Locally successful, they have quickly developed a notoriety that enables them to be directive with their clients.","['Pras, Amandine', 'Turner, Kierian', 'Bol, Toby', 'Olivier, Emmanuelle']","['Digital Audio Arts - University of Lethbridge, Lethbridge, Alberta, Canada', 'School for Advanced Studies in the Social Sciences, Paris, France', 'CNRS Centre Georg Simmel (EHESS), Paris, France']",Audio Education,Talk
131,Using Volterra Series Modeling Techniques to Classify Black-Box Audio Effects,"Digital models of various audio devices are useful for simulating audio processing effects, but developing good models of nonlinear systems can be challenging. This paper reports on the in-progress work of determining attributes of black-box audio devices using Volterra series modeling techniques. In general, modeling an audio effect requires determination of whether the system is linear or nonlinear, time-invariant or –variant, and whether it has memory. For nonlinear systems, we must determine the degree of nonlinearity of the system, and the required parameters of a suitable model. We explain our work in making educated guesses about the order of nonlinearity in a memoryless system and then discuss the extension to nonlinear systems with memory.","['Hoerr, Ethan', 'Maher, Robert C.']","['Montana State University, Bozeman, MT, USA']",Audio Signal Processing,Talk
132,The Effect of the Grid Resolution of Binaural Room Acoustic Auralization on Spatial and Timbral Fidelity,"This paper investigates the effect of the grid resolution of binaural room acoustic auralization on spatial and timbral fidelity. Binaural concert hall stimuli were generated using a virtual acoustics program utilizing image source and ray tracing techniques. Each image source and ray were binaurally synthesized using Lebedev grids of increasing resolution from 6 to 5810 (reference) points. A MUSHRA test was performed where subjects rated the magnitudes of spatial and timbral differences of each stimulus to the reference. Overall, it was found that on the MUSHRA scale, 6 points were perceived to be ""Fair,"" 14 points ""Good,"" and 26 points and above all ""Excellent"" on the grading scale, for both spatial and timbral fidelity.","['Johnson, Dale', 'Lee, Hyunkook']","['University of Huddersfield, Huddersfield, UK']",Spatial Audio,Poster
133,Effect of a Global Metronome on Ensemble Accuracy in Networked Music Performance,"Several rhythmic experiments with pairs drawn from a group of 23 subjects were performed to investigate the effect of a global metronome on the ensemble accuracy in Networked Music Performance (NMP). Artificial delays up to 91 ms were inserted into the audio transmission between the subjects. To investigate the dependencies between delay times, ensemble accuracy and the highly synchronized global metronome, the experiments were evaluated in terms of tempo acceleration, imprecision and subjective judgment of the ensemble play. The results show that the global metronome leads to a stabilization of the tempo acceleration caused by the delay. The imprecision stays constant to a threshold of about 28 ms and 36 ms, depending on the delay compensating strategy the subjects used. Winner of the 147th AES Convention Student Paper Award","['Hupke, Robert', 'Beyer, Lucas', 'Nophut, Marcel', 'Preihs, Stephan', 'Peissig, Jürgen']","['Leibniz Universität Hannover, Hannover, Germany']",Applications in Audio,Talk
134,Classification of HRTFs Using Perceptually Meaningful Frequency Arrays,"Head-related transfer functions (HRTFs) are essential in binaural audio. Because HRTFs are highly individualized and difficult to acquire, much research has been devoted towards improving HRTF performance for the general population. Such research requires a valid and robust method for classifying and comparing HRTFs. This study used a k-nearest neighbor (KNN) classifier to evaluate the ability of several different frequency arrays to characterize HRTFs. The perceptual impact of these frequency arrays was evaluated through a subjective test. Mel-frequency arrays showed the best results in the KNN classification tests while the subjective test results were inconclusive.","['Eley, Nolan']","['New York University, New York, NY, USA']","Spatial Audio, Part 2",Talk
135,Transparent Office Screens Based on Microperforated Foil,"In recent years, providing comfortable working conditions in open office spaces has become a growing challenge. The ever-increasing demand for office work implies the emergence of ever new spaces and the need to use available space, which generates the need for proper interior design. There are many acoustic solutions available on the market that support the acoustic comfort in office spaces by ensuring appropriate levels of privacy and low levels of acoustic background. One of such solutions are desktop screens, which divide employees’ space. These solutions are based mainly on sound absorbing materials, i.e., mineral wool, felt, as well as sound insulating ones, such as glass or MDF. The article presents methods of using microperforated foils for building acoustic screens. The influence of dimensions and parameters of microperforated foil were examined. The method of its assembly as well as the use of layered systems made of microperforated foil and sound insulating material were also considered in this paper.","['Brawata, Krzysztof', 'Baruch, Katarzyna', 'Kamisinski, Tadeusz', 'Chojnacki, Bartlomiej']","['Gorycki & Sznyterman Sp. z o.o., Cracow, Poland', 'AGH University of Science and Technology, Cracow, Poland']",Room Acoustics,Poster
136,Machine Learning Multitrack Gain Mixing of Drums,"There is a body of work in the field of intelligent music production covering a range of specific audio effects. However, there is a distinct lack of any purely machine learning approaches to automatic mixing. This could be due to a lack of suitable data. This paper presents an approach to used human produced audio mixes, along with their source multitrack, to produce the set of mix parameters. The focus will be entirely on the gain mixing of audio drum tracks. Using existing reverse engineering of music production gain parameters, a target mix gain parameter is identified, and these results are fed into a number of machine learning algorithms, along with audio feature vectors of each audio track. This allow for a machine learning prediction approach to audio gain mixing. A random forest approach is taken to perform a multiple output prediction. The prediction results of the random forest approach are then compared to a number of other published automatic gain mixing approaches. The results demonstrate that the random forest gain mixing approach performs similarly to that of a human engineer and outperforms the existing gain mixing approaches.","['Moffat, Dave', 'Sandler, Mark']","['Queen Mary University London, London, UK']",Recording and Production,Talk
137,Use of Wavelet Transform for the Computation of Modal Decay Times in Rooms,"The acoustic behavior of small rooms in the modal frequency band can be characterized by the modal decay times MT60. The paper explores a method for computing modal decay times from measurements of Room Impulse Responses (RIR) based on the wavelet transform. Once the resonance frequencies have been selected, the procedure computes a series of wavelet transforms of the Morlet type with decreasing bandwidth, exploiting the property that Morlet wavelets preserve the time history of energy decay. Then decay times can be calculated either by linear regression of the non-noisy portion of the curve or by nonlinear fitting of a model of decay plus noise. Examples of application of the method to real RIR measurements are shown.","['Magalotti, Roberto', 'Ponteggia, Daniele']","['B&C Speakers S.p.A., Bagno a Ripoli (FI), Italy', 'Audiomatica Srl, Firenze, Italy']",Room Acoustics,Talk
138,Analyzing Loudness Aspects of 4.2 Million Musical Albums in Search of an Optimal Loudness Target for Music Streaming,"In cooperation with music streaming service Tidal, 4.2 million albums were analyzed for loudness aspects such as loudest and softest track loudness. Evidence of development of the loudness war was found and a suggestion for music streaming services to use album normalization at –14 LUFS for mobile platforms and –18 LUFS or lower for stationary platforms was derived from the data set and a limited subject study. Tidal has implemented the recommendation and reports positive results.","['Grimm, Eelco']","['HKU University of the Arts, Utrecht, Netherlands']",Applications in Audio,Poster
139,An Automated Approach to the Application of Reverberation,"The field of intelligent music production has been growing over recent years. There have been several different approaches to automated reverberation. In this paper we automate the parameters of an algorithmic reverb based on analysis of the input signals. Literature is used to produce a set of rules for the application of reverberation, and these rules are then represented directly as direct audio feature. This audio feature representation is then used to control the reverberation parameters from the audio signal in real time.","['Moffat, Dave', 'Sandler, Mark']","['Queen Mary University London, London, UK']","Recording, Production, and Live Sound",Talk
140,An Investigation into the Effectiveness of Room Adaptation Systems: Listening Test Results,"Loudspeaker-room interactions are well known for affecting the perceived sound quality of low frequencies. To solve this problem, different room adaptation systems for adapting a loudspeaker to its acoustic environment have been developed. In this study two listening tests were performed to assess the effectiveness of four different room adaptation systems under different circumstances. The factors investigated include the listening room, loudspeaker, listening position, and listener. The results indicate that listeners’ preference for different adaptation systems is affected by the specific acoustic environment. It was found that the adaptation system based on acoustic power measurement proved to be more preferred, also with stable performance.","['Yu, Pei', 'Liu, Ziyun', 'Zhang, Shufeng', 'Shen, Yong']","['Nanjing University, Nanjing, China']",Applications in Audio,Poster
141,Exploring Preference for Multitrack Mixes Using Statistical Analysis of MIR and Textual Features,"We investigate listener preference in multitrack music production using the Mix Evaluation Dataset, comprised of 184 mixes across 19 songs. Features are extracted from verses and choruses of stereo mixdowns. Each observation is associated with an average listener preference rating and standard deviation of preference ratings. Principal component analysis is performed to analyze how mixes vary within the feature space. We demonstrate that virtually no correlation is found between the embedded features and either average preference or standard deviation of preference. We instead propose using principal component projections as a semantic embedding space by associating each observation with listener comments from the Mix Evaluation Dataset. Initial results disagree with simple descriptions such as “width” or “loudness” for principal component axes.","['Colonel, Joseph', 'Reiss, Joshua D.']","['Queen Mary University of London, London, UK']",Recording and Production,Talk
